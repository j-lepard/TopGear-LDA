{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Automatic Speech Recognition, Diarize and Label\n",
    "\n",
    "Environment = \"whisperx\"\n",
    "\n",
    "* Performance Benchmarks on local\n",
    "* GPU Benchmark: 0.09961056709289551 seconds\n",
    "* Memory Bandwidth Benchmark: 0.2920224666595459 seconds\n",
    "* CPU Benchmark: 13.046526432037354 seconds\n",
    "* Disk Write Benchmark: 2.3364615440368652 seconds\n",
    "* Disk Read Benchmark: 0.05882525444030762 seconds \\n\n",
    "  \n",
    "** all benchmarks are >> faster than Collab with the exception of Disk write.\n",
    "\n",
    "## Setup ⚙️\n",
    "Tested for PyTorch 2.0, Python 3.10 (use other versions at your own risk!)\n",
    "GPU execution requires the NVIDIA libraries cuBLAS 11.x and cuDNN 8.x to be installed on the system. Please refer to the CTranslate2 documentation.\n",
    "\n",
    "1.  Create Python3.10 environment\n",
    "\n",
    "`conda create --name whisperx python=3.10`\n",
    "\n",
    "`conda activate whisperx`\n",
    "\n",
    "2. Install PyTorch, e.g. for Linux and Windows CUDA11.8:\n",
    "   \n",
    "conda install pytorch==2.0.0 torchaudio==2.0.0 pytorch-cuda=11.8 -c pytorch -c nvidia\n",
    "\n",
    "See other methods here.\n",
    "\n",
    "1. Install this repo\n",
    "\n",
    "`pip install git+https://github.com/m-bain/whisperx.git`\n",
    "\n",
    "If already installed, update package to most recent commit\n",
    "\n",
    "`pip install git+https://github.com/m-bain/whisperx.git --upgrade`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess initial audio file\n",
    "convert to Wav using ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted ./audio/Botswana_2024_Audio.mp3 to ./data/Botswana_2024_Audio.wav\n"
     ]
    }
   ],
   "source": [
    "import ffmpeg\n",
    "\n",
    "## 1 - Convert Mp3 to WAV.\n",
    "\n",
    "def convert_m4a_to_mp3(input_file, output_file):\n",
    "    try:\n",
    "        ffmpeg.input(input_file).output(output_file).run(overwrite_output=True)\n",
    "        print(f\"Successfully converted {input_file} to {output_file}\")\n",
    "    except ffmpeg.Error as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "# Input/ output files and usage\n",
    "input_mp3 = './audio/Botswana_2024_Audio.mp3'  # Change this to your mp3 file path\n",
    "output_wav = './data/Botswana_2024_Audio.wav'  # Change this to your desired output wav file path\n",
    "\n",
    "convert_m4a_to_mp3(input_mp3, output_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisperx\n",
    "import gc\n",
    "import os\n",
    "import torch\n",
    "\n",
    "device = \"cuda\"\n",
    "## Full file should be the input (2007 or 2024 file..)\n",
    "audio_file = \"./data/Botswana_2007_Audio.wav\"\n",
    "\n",
    "\n",
    "batch_size = 16 # reduce if low on GPU mem\n",
    "compute_type = \"float16\" # change to \"int8\" if low on GPU mem (may reduce accuracy)\n",
    "without_timestamps= 'True'\n",
    "\n",
    "## Some error handling to ensure that successfully loaded the mp3 file!\n",
    "try:\n",
    "    # Check if the file exists\n",
    "    if not os.path.isfile(audio_file):\n",
    "        raise FileNotFoundError(f\"The file '{audio_file}' does not exist.\")\n",
    "    # Optionally, you can add more checks (like file format) here\n",
    "\n",
    "    print(f\"Successfully accessed the audio file: {audio_file}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisperx\n",
    "import gc\n",
    "import os\n",
    "import torch\n",
    "\n",
    "device = \"cuda\"\n",
    "## Full file should be the input (2007 or 2024 file..)\n",
    "audio_file = \"./audio/Botswana_2007_Audio.wav\"\n",
    "\n",
    "## DEBUGGING, use a small file\n",
    "# audio_file = \"./audio/Intro.wav\"\n",
    "\n",
    "batch_size = 16 # reduce if low on GPU mem\n",
    "compute_type = \"float16\" # change to \"int8\" if low on GPU mem (may reduce accuracy)\n",
    "without_timestamps= 'True'\n",
    "\n",
    "## Some error handling to ensure that successfully loaded the mp3 file!\n",
    "try:\n",
    "    # Check if the file exists\n",
    "    if not os.path.isfile(audio_file):\n",
    "        raise FileNotFoundError(f\"The file '{audio_file}' does not exist.\")\n",
    "    # Optionally, you can add more checks (like file format) here\n",
    "\n",
    "    print(f\"Successfully accessed the audio file: {audio_file}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BATCH PROCESS: Transcript - Align - Diarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whisperx in the Terminal\n",
    "This seemed to work on a single file VERY fast! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from HF_token import TOKEN_ID\n",
    "# Set the path to your directory\n",
    "directory = \"./audio/\"\n",
    "\n",
    "# Iterate through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".wav\"):  # Check for .wav files\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Construct and run the whisperx command for each file\n",
    "        command = f\"whisperx {filepath} --model large-v2 --diarize --highlight_words True --hf_token {TOKEN_ID} --output_dir ./outputs\"\n",
    "        os.system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consolidate the Diarized JSON files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.467</td>\n",
       "      <td>23.068</td>\n",
       "      <td>Hello, hello, and welcome.</td>\n",
       "      <td>[{'word': 'Hello,', 'start': 21.467, 'end': 21...</td>\n",
       "      <td>SPEAKER_04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.108</td>\n",
       "      <td>24.029</td>\n",
       "      <td>Thank you very much.</td>\n",
       "      <td>[{'word': 'Thank', 'start': 23.108, 'end': 23....</td>\n",
       "      <td>SPEAKER_05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.049</td>\n",
       "      <td>34.256</td>\n",
       "      <td>Now, as you know, the producers on this show l...</td>\n",
       "      <td>[{'word': 'Now,', 'start': 24.049, 'end': 24.1...</td>\n",
       "      <td>SPEAKER_05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.597</td>\n",
       "      <td>39.640</td>\n",
       "      <td>Then they set unbelievably hard tasks to do to...</td>\n",
       "      <td>[{'word': 'Then', 'start': 34.597, 'end': 34.7...</td>\n",
       "      <td>SPEAKER_05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.900</td>\n",
       "      <td>40.080</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>[{'word': 'Yeah.', 'start': 39.9, 'end': 40.08...</td>\n",
       "      <td>SPEAKER_06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>377.117</td>\n",
       "      <td>378.638</td>\n",
       "      <td>And that instrument's a bit wobbly.</td>\n",
       "      <td>[{'word': 'And', 'start': 377.117, 'end': 377....</td>\n",
       "      <td>SPEAKER_03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>378.658</td>\n",
       "      <td>382.560</td>\n",
       "      <td>Apart from that, everything that's actually im...</td>\n",
       "      <td>[{'word': 'Apart', 'start': 378.658, 'end': 37...</td>\n",
       "      <td>SPEAKER_03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>383.560</td>\n",
       "      <td>386.882</td>\n",
       "      <td>Apart from the handbrake, which I can pull lik...</td>\n",
       "      <td>[{'word': 'Apart', 'start': 383.56, 'end': 383...</td>\n",
       "      <td>SPEAKER_03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>388.453</td>\n",
       "      <td>393.758</td>\n",
       "      <td>Nevertheless, because we were on tarmac roads...</td>\n",
       "      <td>[{'word': 'Nevertheless,', 'start': 388.453, '...</td>\n",
       "      <td>SPEAKER_05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>394.258</td>\n",
       "      <td>395.379</td>\n",
       "      <td>Building up speed now.</td>\n",
       "      <td>[{'word': 'Building', 'start': 394.258, 'end':...</td>\n",
       "      <td>SPEAKER_05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      start      end                                               text  \\\n",
       "0    21.467   23.068                         Hello, hello, and welcome.   \n",
       "1    23.108   24.029                               Thank you very much.   \n",
       "2    24.049   34.256  Now, as you know, the producers on this show l...   \n",
       "3    34.597   39.640  Then they set unbelievably hard tasks to do to...   \n",
       "4    39.900   40.080                                              Yeah.   \n",
       "..      ...      ...                                                ...   \n",
       "95  377.117  378.638                And that instrument's a bit wobbly.   \n",
       "96  378.658  382.560  Apart from that, everything that's actually im...   \n",
       "97  383.560  386.882  Apart from the handbrake, which I can pull lik...   \n",
       "98  388.453  393.758   Nevertheless, because we were on tarmac roads...   \n",
       "99  394.258  395.379                             Building up speed now.   \n",
       "\n",
       "                                                words     speaker  \n",
       "0   [{'word': 'Hello,', 'start': 21.467, 'end': 21...  SPEAKER_04  \n",
       "1   [{'word': 'Thank', 'start': 23.108, 'end': 23....  SPEAKER_05  \n",
       "2   [{'word': 'Now,', 'start': 24.049, 'end': 24.1...  SPEAKER_05  \n",
       "3   [{'word': 'Then', 'start': 34.597, 'end': 34.7...  SPEAKER_05  \n",
       "4   [{'word': 'Yeah.', 'start': 39.9, 'end': 40.08...  SPEAKER_06  \n",
       "..                                                ...         ...  \n",
       "95  [{'word': 'And', 'start': 377.117, 'end': 377....  SPEAKER_03  \n",
       "96  [{'word': 'Apart', 'start': 378.658, 'end': 37...  SPEAKER_03  \n",
       "97  [{'word': 'Apart', 'start': 383.56, 'end': 383...  SPEAKER_03  \n",
       "98  [{'word': 'Nevertheless,', 'start': 388.453, '...  SPEAKER_05  \n",
       "99  [{'word': 'Building', 'start': 394.258, 'end':...  SPEAKER_05  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "\n",
    "# Directory containing the JSON files\n",
    "json_directory = 'outputs/'\n",
    "\n",
    "# Get a list of all JSON files in the directory\n",
    "json_files = glob.glob(os.path.join(json_directory, '*.json'))\n",
    "\n",
    "# Initialize a list to hold all DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Iterate through each JSON file and merge segments\n",
    "for json_file in json_files:\n",
    "\twith open(json_file, 'r') as file:\n",
    "\t\tdata = json.load(file)\n",
    "\t\t# Convert the \"segments\" part of the JSON data to a DataFrame\n",
    "\t\tdf = pd.DataFrame(data[\"segments\"])\n",
    "\t\tdf_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "diarized_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Export\n",
    "diarized_df.to_csv('./data/00.diarzed_output_no_names.csv')\n",
    "\n",
    "# Display the consolidated DataFrame\n",
    "diarized_df.head(100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the Speaker names to the labels\n",
    "\n",
    "'''\n",
    "Speaker 00 = Narrator\n",
    "Speaker 01 = Hammond\n",
    "Speaker 02 = Hammond\n",
    "Speaker 03 = May\n",
    "Speaker 04 = Clarkson\n",
    "Speaker 05 = Clarkson\n",
    "06 = Hammond\n",
    "07 = Hammond\n",
    "08 = Hammond\n",
    "09 = ?\n",
    "\n",
    "'''\n",
    "\n",
    "diarized_df['speaker'] = diarized_df['speaker'].replace('SPEAKER_00', 'Narrator')\n",
    "diarized_df['speaker'] = diarized_df['speaker'].replace('SPEAKER_01', 'Hammond')\n",
    "diarized_df['speaker'] = diarized_df['speaker'].replace('SPEAKER_02', 'Hammond')\n",
    "\n",
    "diarized_df['speaker'] = diarized_df['speaker'].replace('SPEAKER_03', 'May')\n",
    "diarized_df['speaker'] = diarized_df['speaker'].replace('SPEAKER_04', 'Clarkson')\n",
    "diarized_df['speaker'] = diarized_df['speaker'].replace('SPEAKER_05', 'Clarkson')\n",
    "\n",
    "diarized_df['speaker'] = diarized_df['speaker'].replace('SPEAKER_06', 'Hammond')\n",
    "diarized_df['speaker'] = diarized_df['speaker'].replace('SPEAKER_07', 'Hammond')\n",
    "diarized_df['speaker'] = diarized_df['speaker'].replace('SPEAKER_08', 'Hammond')\n",
    "\n",
    "diarized_df.head(100)\n",
    "\n",
    "# Export\n",
    "diarized_df.to_csv('./data/01.diarzed_output_named.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: LDA (Latent Dirichlet Allocation) Preparation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the diarized data from (created previously)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Import\n",
    "diarized_df = pd.read_csv('./data/01.diarzed_output_named.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21.467</td>\n",
       "      <td>23.068</td>\n",
       "      <td>Hello, hello, and welcome.</td>\n",
       "      <td>[{'word': 'Hello,', 'start': 21.467, 'end': 21...</td>\n",
       "      <td>Clarkson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23.108</td>\n",
       "      <td>24.029</td>\n",
       "      <td>Thank you very much.</td>\n",
       "      <td>[{'word': 'Thank', 'start': 23.108, 'end': 23....</td>\n",
       "      <td>Clarkson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>24.049</td>\n",
       "      <td>34.256</td>\n",
       "      <td>Now, as you know, the producers on this show l...</td>\n",
       "      <td>[{'word': 'Now,', 'start': 24.049, 'end': 24.1...</td>\n",
       "      <td>Clarkson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>34.597</td>\n",
       "      <td>39.640</td>\n",
       "      <td>Then they set unbelievably hard tasks to do to...</td>\n",
       "      <td>[{'word': 'Then', 'start': 34.597, 'end': 34.7...</td>\n",
       "      <td>Clarkson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>39.900</td>\n",
       "      <td>40.080</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>[{'word': 'Yeah.', 'start': 39.9, 'end': 40.08...</td>\n",
       "      <td>Hammond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>1035</td>\n",
       "      <td>3544.028</td>\n",
       "      <td>3544.468</td>\n",
       "      <td>He's right.</td>\n",
       "      <td>[{'word': \"He's\", 'start': 3544.028, 'end': 35...</td>\n",
       "      <td>Clarkson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>1036</td>\n",
       "      <td>3545.329</td>\n",
       "      <td>3547.850</td>\n",
       "      <td>You've replaced all the electrics in that car.</td>\n",
       "      <td>[{'word': \"You've\", 'start': 3545.329, 'end': ...</td>\n",
       "      <td>Clarkson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>1037</td>\n",
       "      <td>3554.833</td>\n",
       "      <td>3563.498</td>\n",
       "      <td>Tomorrow night at 8.50, it's more from the Top...</td>\n",
       "      <td>[{'word': 'Tomorrow', 'start': 3554.833, 'end'...</td>\n",
       "      <td>Narrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>1038</td>\n",
       "      <td>3563.818</td>\n",
       "      <td>3566.059</td>\n",
       "      <td>Let's hope they bring enough glove compartment...</td>\n",
       "      <td>[{'word': \"Let's\", 'start': 3563.818, 'end': 3...</td>\n",
       "      <td>Narrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>1039</td>\n",
       "      <td>3566.399</td>\n",
       "      <td>3568.340</td>\n",
       "      <td>And up next, it's Sherlock on three.</td>\n",
       "      <td>[{'word': 'And', 'start': 3566.399, 'end': 356...</td>\n",
       "      <td>Narrator</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0     start       end  \\\n",
       "0              0    21.467    23.068   \n",
       "1              1    23.108    24.029   \n",
       "2              2    24.049    34.256   \n",
       "3              3    34.597    39.640   \n",
       "4              4    39.900    40.080   \n",
       "...          ...       ...       ...   \n",
       "1035        1035  3544.028  3544.468   \n",
       "1036        1036  3545.329  3547.850   \n",
       "1037        1037  3554.833  3563.498   \n",
       "1038        1038  3563.818  3566.059   \n",
       "1039        1039  3566.399  3568.340   \n",
       "\n",
       "                                                   text  \\\n",
       "0                            Hello, hello, and welcome.   \n",
       "1                                  Thank you very much.   \n",
       "2     Now, as you know, the producers on this show l...   \n",
       "3     Then they set unbelievably hard tasks to do to...   \n",
       "4                                                 Yeah.   \n",
       "...                                                 ...   \n",
       "1035                                        He's right.   \n",
       "1036     You've replaced all the electrics in that car.   \n",
       "1037  Tomorrow night at 8.50, it's more from the Top...   \n",
       "1038  Let's hope they bring enough glove compartment...   \n",
       "1039               And up next, it's Sherlock on three.   \n",
       "\n",
       "                                                  words   speaker  \n",
       "0     [{'word': 'Hello,', 'start': 21.467, 'end': 21...  Clarkson  \n",
       "1     [{'word': 'Thank', 'start': 23.108, 'end': 23....  Clarkson  \n",
       "2     [{'word': 'Now,', 'start': 24.049, 'end': 24.1...  Clarkson  \n",
       "3     [{'word': 'Then', 'start': 34.597, 'end': 34.7...  Clarkson  \n",
       "4     [{'word': 'Yeah.', 'start': 39.9, 'end': 40.08...   Hammond  \n",
       "...                                                 ...       ...  \n",
       "1035  [{'word': \"He's\", 'start': 3544.028, 'end': 35...  Clarkson  \n",
       "1036  [{'word': \"You've\", 'start': 3545.329, 'end': ...  Clarkson  \n",
       "1037  [{'word': 'Tomorrow', 'start': 3554.833, 'end'...  Narrator  \n",
       "1038  [{'word': \"Let's\", 'start': 3563.818, 'end': 3...  Narrator  \n",
       "1039  [{'word': 'And', 'start': 3566.399, 'end': 356...  Narrator  \n",
       "\n",
       "[1040 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df = diarized_df.copy()\n",
    "# Preprocessing steps for LDA analysis\n",
    "\n",
    "preprocessed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all the libraries required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "\n",
    "#Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "#spacy\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#vis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "### Cant remember why needed this ... \n",
    "import locale\n",
    "def getpreferredencoding(do_setlocale=True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Below is a suggestion from gpt. \n",
    "from nltk.corpus.util import LazyCorpusLoader\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "# 1. Remove emails, newline characters, and non-alphabetic characters\n",
    "preprocessed_df['cleaned_text'] = preprocessed_df['text'].str.replace(r'\\S+@\\S+', '', regex=True)\n",
    "preprocessed_df['cleaned_text'] = preprocessed_df['cleaned_text'].str.replace(r'http\\S+|www\\S+', '', regex=True)\n",
    "preprocessed_df['cleaned_text'] = preprocessed_df['cleaned_text'].str.replace(r'\\n', ' ', regex=True)\n",
    "preprocessed_df['cleaned_text'] = preprocessed_df['cleaned_text'].str.replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "\n",
    "# 2. Convert to lowercase\n",
    "preprocessed_df['cleaned_text'] = preprocessed_df['cleaned_text'].str.lower()\n",
    "\n",
    "# 3. Tokenize the text\n",
    "preprocessed_df['tokens'] = preprocessed_df['cleaned_text'].apply(lambda x: gensim.utils.simple_preprocess(x, deacc=True))\n",
    "\n",
    "# 4. Remove stopwords\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "preprocessed_df['tokens'] = preprocessed_df['tokens'].apply(lambda x: [word for word in x if word not in stopwords])\n",
    "\n",
    "# 5. Lemmatize the tokens\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "preprocessed_df['lemmatized_tokens'] = preprocessed_df['tokens'].apply(lambda x: [token.lemma_ for token in nlp(\" \".join(x)) if token.pos_ in [\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]])\n",
    "\n",
    "# 6. Remove tokens that are less than 3 characters long\n",
    "preprocessed_df['lemmatized_tokens'] = preprocessed_df['lemmatized_tokens'].apply(lambda x: [word for word in x if len(word) >= 3])\n",
    "\n",
    "# 7. Remove rows where the list length in lemmatized_tokens is 0\n",
    "preprocessed_df = preprocessed_df[preprocessed_df['lemmatized_tokens'].apply(len) > 0]\n",
    "\n",
    "#  Tested each step with a few preprocessed_df.iloc[6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>speaker</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23.108</td>\n",
       "      <td>24.029</td>\n",
       "      <td>Thank you very much.</td>\n",
       "      <td>[{'word': 'Thank', 'start': 23.108, 'end': 23....</td>\n",
       "      <td>Clarkson</td>\n",
       "      <td>thank you very much</td>\n",
       "      <td>[thank, much]</td>\n",
       "      <td>[thank, much]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>24.049</td>\n",
       "      <td>34.256</td>\n",
       "      <td>Now, as you know, the producers on this show l...</td>\n",
       "      <td>[{'word': 'Now,', 'start': 24.049, 'end': 24.1...</td>\n",
       "      <td>Clarkson</td>\n",
       "      <td>now as you know the producers on this show lik...</td>\n",
       "      <td>[know, producers, show, like, give, us, challe...</td>\n",
       "      <td>[know, producer, show, give, challenge, specif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>34.597</td>\n",
       "      <td>39.640</td>\n",
       "      <td>Then they set unbelievably hard tasks to do to...</td>\n",
       "      <td>[{'word': 'Then', 'start': 34.597, 'end': 34.7...</td>\n",
       "      <td>Clarkson</td>\n",
       "      <td>then they set unbelievably hard tasks to do to...</td>\n",
       "      <td>[set, unbelievably, hard, tasks, see, one, us,...</td>\n",
       "      <td>[set, unbelievably, hard, task, see, get, good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>40.541</td>\n",
       "      <td>44.043</td>\n",
       "      <td>This week, for a Top Gear special, they came u...</td>\n",
       "      <td>[{'word': 'This', 'start': 40.541, 'end': 40.7...</td>\n",
       "      <td>Hammond</td>\n",
       "      <td>this week for a top gear special they came up ...</td>\n",
       "      <td>[week, top, gear, special, came, real, humdinger]</td>\n",
       "      <td>[week, top, gear, special, come, real, humdinger]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>44.423</td>\n",
       "      <td>50.408</td>\n",
       "      <td>They gave each of us 1,500 quid and told us to...</td>\n",
       "      <td>[{'word': 'They', 'start': 44.423, 'end': 44.5...</td>\n",
       "      <td>Hammond</td>\n",
       "      <td>they gave each of us  quid and told us to go t...</td>\n",
       "      <td>[gave, us, quid, told, us, go, africa, buy, car]</td>\n",
       "      <td>[give, quid, tell, buy, car]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   start     end  \\\n",
       "1           1  23.108  24.029   \n",
       "2           2  24.049  34.256   \n",
       "3           3  34.597  39.640   \n",
       "5           5  40.541  44.043   \n",
       "6           6  44.423  50.408   \n",
       "\n",
       "                                                text  \\\n",
       "1                               Thank you very much.   \n",
       "2  Now, as you know, the producers on this show l...   \n",
       "3  Then they set unbelievably hard tasks to do to...   \n",
       "5  This week, for a Top Gear special, they came u...   \n",
       "6  They gave each of us 1,500 quid and told us to...   \n",
       "\n",
       "                                               words   speaker  \\\n",
       "1  [{'word': 'Thank', 'start': 23.108, 'end': 23....  Clarkson   \n",
       "2  [{'word': 'Now,', 'start': 24.049, 'end': 24.1...  Clarkson   \n",
       "3  [{'word': 'Then', 'start': 34.597, 'end': 34.7...  Clarkson   \n",
       "5  [{'word': 'This', 'start': 40.541, 'end': 40.7...   Hammond   \n",
       "6  [{'word': 'They', 'start': 44.423, 'end': 44.5...   Hammond   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "1                                thank you very much   \n",
       "2  now as you know the producers on this show lik...   \n",
       "3  then they set unbelievably hard tasks to do to...   \n",
       "5  this week for a top gear special they came up ...   \n",
       "6  they gave each of us  quid and told us to go t...   \n",
       "\n",
       "                                              tokens  \\\n",
       "1                                      [thank, much]   \n",
       "2  [know, producers, show, like, give, us, challe...   \n",
       "3  [set, unbelievably, hard, tasks, see, one, us,...   \n",
       "5  [week, top, gear, special, came, real, humdinger]   \n",
       "6   [gave, us, quid, told, us, go, africa, buy, car]   \n",
       "\n",
       "                                   lemmatized_tokens  \n",
       "1                                      [thank, much]  \n",
       "2  [know, producer, show, give, challenge, specif...  \n",
       "3  [set, unbelievably, hard, task, see, get, good...  \n",
       "5  [week, top, gear, special, come, real, humdinger]  \n",
       "6                       [give, quid, tell, buy, car]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the preprocessed dataframe\n",
    "preprocessed_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the Pre Processed DF to CSV\n",
    "\n",
    "* removed emails\n",
    "* converted to lower\n",
    "* remove stop words\n",
    "* tokenized and lemmatize\n",
    "* remove tokens <3 char\n",
    "* remove null dictionaries (rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocessed_df.to_csv(\"./data/03.preprocess_completed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data frame into 3 (one per presenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>speaker</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23.108</td>\n",
       "      <td>24.029</td>\n",
       "      <td>Thank you very much.</td>\n",
       "      <td>[{'word': 'Thank', 'start': 23.108, 'end': 23....</td>\n",
       "      <td>Clarkson</td>\n",
       "      <td>thank you very much</td>\n",
       "      <td>[thank, much]</td>\n",
       "      <td>[thank, much]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>24.049</td>\n",
       "      <td>34.256</td>\n",
       "      <td>Now, as you know, the producers on this show l...</td>\n",
       "      <td>[{'word': 'Now,', 'start': 24.049, 'end': 24.1...</td>\n",
       "      <td>Clarkson</td>\n",
       "      <td>now as you know the producers on this show lik...</td>\n",
       "      <td>[know, producers, show, like, give, us, challe...</td>\n",
       "      <td>[know, producer, show, give, challenge, specif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>34.597</td>\n",
       "      <td>39.640</td>\n",
       "      <td>Then they set unbelievably hard tasks to do to...</td>\n",
       "      <td>[{'word': 'Then', 'start': 34.597, 'end': 34.7...</td>\n",
       "      <td>Clarkson</td>\n",
       "      <td>then they set unbelievably hard tasks to do to...</td>\n",
       "      <td>[set, unbelievably, hard, tasks, see, one, us,...</td>\n",
       "      <td>[set, unbelievably, hard, task, see, get, good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>100.860</td>\n",
       "      <td>102.060</td>\n",
       "      <td>It is a Lancia Beta.</td>\n",
       "      <td>[{'word': 'It', 'start': 100.86, 'end': 100.96...</td>\n",
       "      <td>Clarkson</td>\n",
       "      <td>it is a lancia beta</td>\n",
       "      <td>[lancia, beta]</td>\n",
       "      <td>[beta]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>102.220</td>\n",
       "      <td>102.440</td>\n",
       "      <td>Coupé, 1981.</td>\n",
       "      <td>[{'word': 'Coupé,', 'start': 102.22, 'end': 10...</td>\n",
       "      <td>Clarkson</td>\n",
       "      <td>coup</td>\n",
       "      <td>[coup]</td>\n",
       "      <td>[coup]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0    start      end  \\\n",
       "1            1   23.108   24.029   \n",
       "2            2   24.049   34.256   \n",
       "3            3   34.597   39.640   \n",
       "16          16  100.860  102.060   \n",
       "17          17  102.220  102.440   \n",
       "\n",
       "                                                 text  \\\n",
       "1                                Thank you very much.   \n",
       "2   Now, as you know, the producers on this show l...   \n",
       "3   Then they set unbelievably hard tasks to do to...   \n",
       "16                               It is a Lancia Beta.   \n",
       "17                                       Coupé, 1981.   \n",
       "\n",
       "                                                words   speaker  \\\n",
       "1   [{'word': 'Thank', 'start': 23.108, 'end': 23....  Clarkson   \n",
       "2   [{'word': 'Now,', 'start': 24.049, 'end': 24.1...  Clarkson   \n",
       "3   [{'word': 'Then', 'start': 34.597, 'end': 34.7...  Clarkson   \n",
       "16  [{'word': 'It', 'start': 100.86, 'end': 100.96...  Clarkson   \n",
       "17  [{'word': 'Coupé,', 'start': 102.22, 'end': 10...  Clarkson   \n",
       "\n",
       "                                         cleaned_text  \\\n",
       "1                                 thank you very much   \n",
       "2   now as you know the producers on this show lik...   \n",
       "3   then they set unbelievably hard tasks to do to...   \n",
       "16                                it is a lancia beta   \n",
       "17                                              coup    \n",
       "\n",
       "                                               tokens  \\\n",
       "1                                       [thank, much]   \n",
       "2   [know, producers, show, like, give, us, challe...   \n",
       "3   [set, unbelievably, hard, tasks, see, one, us,...   \n",
       "16                                     [lancia, beta]   \n",
       "17                                             [coup]   \n",
       "\n",
       "                                    lemmatized_tokens  \n",
       "1                                       [thank, much]  \n",
       "2   [know, producer, show, give, challenge, specif...  \n",
       "3   [set, unbelievably, hard, task, see, get, good...  \n",
       "16                                             [beta]  \n",
       "17                                             [coup]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a new DataFrame for each speaker\n",
    "May_df = preprocessed_df[preprocessed_df['speaker'] == 'May']\n",
    "Clarkson_df = preprocessed_df[preprocessed_df['speaker'] == 'Clarkson']\n",
    "Hammond_df = preprocessed_df[preprocessed_df['speaker'] == 'Hammond']\n",
    "\n",
    "# Display the first few rows of each DataFrame (optional)\n",
    "# May_df.head()\n",
    "\n",
    "Clarkson_df.head()\n",
    "\n",
    "# Hammond_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the DF to a LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['week', 'top', 'gear', 'special', 'come', 'real', 'humdinger'], ['give', 'quid', 'tell', 'buy', 'car'], ['hell', 'man'], ['much', 'well', 'nick'], ['much', 'change', 'buy', 'many', 'bean'], ['much', 'simple', 'get'], ['get', 'move', 'part', 'year'], ['horsepower'], ['sport', 'version', 'want', 'lairy'], ['bit', 'thick'], ['sorry'], ['think', 'car', 'inspire', 'latterly', 'build', 'become', 'rubbish'], ['course', 'indirectly'], ['quite', 'lot', 'reasonably', 'average', 'car', 'owe'], ['brake', 'terrible', 'work', 'wheel'], ['work', 'well', 'wheel', 'wheel'], ['overtake', 'truck'], ['pull', 'slipstream'], ['really', 'come'], ['still', 'truck'], ['still', 'truck'], ['happy', 'car', 'world'], ['call', 'oliver'], ['ever', 'name', 'car', 'top'], ['wish', 'say'], ['know'], ['horn'], ['oliver', 'get', 'cold'], ['listen'], ['fun', 'discover', 'travel', 'bill'], ['take', 'look', 'car'], ['massive'], ['knock', 'oliver'], ['knock', 'car'], ['fine', 'fine', 'call'], ['oliver', 'think', 'talk'], ['give', 'name'], ['give', 'car', 'name'], ['come', 'oliver'], ['hang', 'hang'], ['say', 'love'], ['set', 'fire'], ['need', 'maybe'], ['take', 'hubcap', 'really', 'protect', 'hub'], ['fine'], ['really', 'work'], ['old', 'glass'], ['thin', 'glass'], ['beer'], ['thank', 'mate'], ['lose', 'enough', 'weight'], ['next', 'morning', 'edge', 'salt', 'pan', 'think', 'come', 'attack', 'bond', 'villain', 'turn', 'vicepresident'], ['ride'], ['well', 'official', 'rover', 'couple', 'policeman', 'motorbike'], ['amazed', 'hear', 'plan'], ['never', 'know', 'car'], ['first', 'time', 'think'], ['really'], ['really'], ['interesting'], ['smile', 'stop'], ['buoy', 'vice', 'president', 'optimism', 'set'], ['plough', 'little', 'opel', 'well'], ['skip'], ['boom'], ['car', 'bear'], ['look', 'jamess', 'rear', 'wheel', 'dig', 'long', 'way'], ['always', 'beetle', 'jame'], ['wait'], ['sink'], ['nudge'], ['crash'], ['remain', 'troublefree', 'bad', 'news'], ['far'], ['horrible'], ['keep', 'keep', 'keep'], ['keep'], ['describe'], ['think', 'mud'], ['know'], ['interesting', 'come', 'look', 'island'], ['suppose'], ['islands'], ['amazing'], ['stick', 'time'], ['always', 'want', 'see'], ['kind', 'witty'], ['meanwhile', 'unmodified', 'cadet', 'adjust', 'quarter', 'light', 'bit'], ['inch'], ['well'], ['feel', 'heat'], ['nice'], ['close', 'point', 'much', 'pull', 'air', 'get', 'fresh', 'air', 'nice'], ['actually'], ['conk'], ['get', 'power', 'drive'], ['remember', 'man', 'say'], ['breakdown'], ['nice', 'time'], ['die'], ['get', 'say', 'nice', 'piece'], ['know', 'around'], ['car', 'crab'], ['track', 'troentruve'], ['worried', 'tracking', 'look'], ['know', 'jeremy', 'eventually', 'catch', 'drive'], ['see', 'mirror'], ['let', 'beetle'], ['beetle'], ['let', 'beetle'], ['let', 'beetle'], ['want', 'beetle', 'pounce', 'stray'], ['gutte'], ['convoy', 'strength', 'press', 'apart', 'occasionally'], ['turn'], ['turn', 'batterys', 'start'], ['turn', 'start'], ['let', 'beautiful', 'silence'], ['life'], ['mate', 'ever', 'think'], ['genuinely', 'proud'], ['get', 'goosebump'], ['obviously', 'recognise', 'truly', 'classy', 'car'], ['keen', 'get', 'fire', 'engine'], ['say'], ['stupid', 'thing', 'say'], ['annoyingly', 'couple', 'local', 'know'], ['drive', 'african', 'stig', 'rally', 'stage', 'driedup', 'riverbe', 'mile', 'away'], ['pack', 'spectator', 'stand', 'first'], ['mile', 'hour'], ['know', 'new', 'horsepower'], ['eminent'], ['come', 'joggle', 'stig', 'cousin'], ['enjoy'], ['minute', 'second'], ['think', 'good', 'benchmark', 'try', 'beat'], ['dust', 'fire'], ['turn'], ['look'], ['hell', 'difficulty', 'though'], ['maybe', 'start'], ['jeremy'], ['right', 'though'], ['engine'], ['cant'], ['break', 'lance', 'fix'], ['arrive', 'woe'], ['forget'], ['fuel', 'can'], ['town', 'maun', 'mile', 'away', 'little', 'fuel', 'crow', 'fly'], ['really', 'see', 'cope', 'offroad'], ['get', 'try', 'keep', 'distance', 'save', 'fuel', 'get'], ['opel', 'absolutely', 'shone'], ['precious', 'fuel', 'burn', 'away', 'carve', 'straight', 'path', 'possible'], ['guy', 'know', 'drive'], ['plant'], ['weed'], ['grow', 'locally', 'hallucinogenic'], ['say'], ['car', 'get', 'stick', 'put', 'money', 'lance'], ['mate'], ['sorry'], ['darkness', 'fall', 'find', 'road', 'man'], ['stage', 'even', 'oliver', 'suffer'], ['use', 'light'], ['alternator', 'pack', 'full', 'dirt', 'dust'], ['put', 'light', 'light', 'engine', 'die'], ['actually', 'get', 'bring', 'camera', 'light', 'talk', 'torch', 'use', 'light', 'road', 'ahead', 'talk'], ['finally', 'roll', 'man'], ['line'], ['grownup', 'honestly'], ['lot'], ['make', 'angry'], ['call', 'badg', 'death'], ['suppose', 'practice', 'least', 'lion', 'drill'], ['lion', 'come'], ['protect'], ['decide', 'irritate', 'jeremy'], ['defeat', 'well', 'know', 'tarpaulin', 'almost', 'military', 'protective', 'capability'], ['often', 'see', 'people', 'war', 'zone', 'drape', 'tarpaulin'], ['make'], ['get', 'thick'], ['think', 'big'], ['ignore', 'make'], ['cow', 'head'], ['also', 'attract', 'lion', 'tiger', 'effectively', 'become', 'burger', 'drive'], ['make', 'sure', 'lion', 'miss', 'whopper'], ['whole', 'lion'], ['smell', 'really', 'beautiful'], ['also', 'attach', 'car'], ['make', 'merry', 'paint'], ['afternoon', 'leave', 'man', 'head'], ['police', 'car'], ['thank'], ['help', 'brake'], ['lose', 'skull'], ['sorry', 'hit', 'throttle'], ['right'], ['big', 'thing'], ['moon', 'leave', 'animal', 'baby', 'back'], ['attack'], ['look'], ['look'], ['jeremy', 'rubbish', 'commentary'], ['live'], ['look', 'sorry'], ['camp', 'service', 'car', 'hatch', 'plan'], ['cow', 'head'], ['work', 'boat'], ['love', 'think'], ['thank'], ['useful'], ['thank'], ['brilliant'], ['want', 'stay', 'horse', 'sit'], ['question', 'ever', 'ask'], ['horse', 'either'], ['cow'], ['hang'], ['bag', 'tent'], ['tent'], ['man', 'get'], ['whole'], ['iron'], ['think', 'bent', 'steering', 'bit'], ['shallow', 'reed', 'fool'], ['get', 'drive', 'water', 'get'], ['frustrated', 'drive', 'river', 'bored'], ['fair', 'bit', 'offroade', 'know', 'enough', 'place'], ['wrong'], ['carry'], ['meanwhile', 'use', 'patience', 'find', 'proper', 'crossing', 'point'], ['technique', 'fording', 'river', 'even', 'proper', 'ford'], ['get', 'keep', 'enough', 'speed', 'push', 'bow', 'wave', 'use', 'power', 'get', 'engine'], ['come'], ['come', 'come'], ['stall'], ['open', 'door'], ['come'], ['come'], ['float'], ['float'], ['float'], ['oliver'], ['get', 'bit', 'water'], ['good'], ['need', 'rifle'], ['local', 'tourist', 'truck', 'pull', 'laugh', 'hyena', 'arrive'], ['gave', 'diagnosis'], ['fix'], ['leave'], ['back'], ['here', 'good', 'thing'], ['remember'], ['get', 'brake'], ['pedal', 'straight', 'floor', 'declutch', 'stop', 'tread', 'foot'], ['use', 'handbrake'], ['soon', 'hit', 'tarmac', 'start', 'hope'], ['mile'], ['cross'], ['stick', 'second', 'second'], ['really', 'surprising', 'happen'], ['really', 'relax'], ['get', 'brake'], ['wait'], ['wait', 'see', 'car', 'arrive'], ['engine'], ['beetle'], ['almost', 'pleased'], ['excellent'], ['possible', 'measure'], ['surprising'], ['bad']]\n"
     ]
    }
   ],
   "source": [
    "Clarkson_cleaned_texts = Clarkson_df[\"lemmatized_tokens\"].to_list()\n",
    "May_cleaned_texts = May_df[\"lemmatized_tokens\"].to_list()\n",
    "Hammond_cleaned_texts = Hammond_df[\"lemmatized_tokens\"].to_list()\t\n",
    "\n",
    "\n",
    "print(Hammond_cleaned_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Create the Corpora, Dictionary & LDA\n",
    "\n",
    "There are 3 data frames, so create ensure consistent and efficient treatment, create a function to pass each df through the same series of steps. These include: \n",
    "\n",
    "1. create the dictionary of terms\n",
    "2. create the corpus (count of each dictionary term)\n",
    "3. create the LDA Model\n",
    "4. run the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary for May:\n",
      "Dictionary<379 unique tokens: ['condition', 'build', 'drive', 'fourwheel', 'offroad']...>\n",
      "Corpus for May:\n",
      "[[(0, 1)], [(1, 1), (2, 1), (3, 1), (4, 1), (5, 1)], [(6, 1), (7, 1), (8, 1), (9, 1), (10, 1)], [(11, 1), (12, 1)], [(13, 1), (14, 1)], [(15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1)], [(11, 1), (12, 1), (22, 1)], [(24, 1), (25, 1)], [(26, 1), (27, 1)], [(28, 1)], [(29, 1)], [(30, 1), (31, 1)], [(32, 1), (33, 1)], [(34, 1), (35, 1)], [(11, 1), (36, 1), (37, 1), (38, 1)], [(39, 1)], [(40, 1)], [(41, 1)], [(42, 1)], [(35, 1), (43, 1), (44, 1)], [(22, 1)], [(45, 2), (46, 1), (47, 1), (48, 1)], [(47, 1)], [(49, 1)], [(31, 1), (39, 1), (43, 2), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1)], [(59, 1), (60, 1), (61, 1), (62, 1)], [(21, 1), (25, 1), (56, 1), (63, 1), (64, 1), (65, 1), (66, 1)], [(67, 1), (68, 1), (69, 1)], [(70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1)], [(76, 1), (77, 1), (78, 1)], [(51, 1), (62, 1), (67, 1), (79, 1), (80, 1), (81, 1)], [(72, 1), (79, 1), (82, 1), (83, 1)], [(84, 1)], [(83, 1), (85, 1)], [(41, 1), (86, 1)], [(21, 1), (87, 1), (88, 1)], [(89, 1), (90, 1), (91, 1)], [(62, 1), (92, 1), (93, 1), (94, 1)], [(95, 1)], [(21, 1), (34, 1), (96, 1), (97, 1), (98, 1), (99, 1)], [(100, 1), (101, 1)], [(40, 1), (62, 1), (102, 1)], [(103, 1), (104, 1), (105, 1)], [(106, 1), (107, 1)], [(108, 1), (109, 1), (110, 1), (111, 1)], [(62, 1), (112, 1)], [(9, 1)], [(37, 1), (51, 1), (54, 1), (113, 1), (114, 1)], [(43, 1), (115, 1)], [(116, 1), (117, 1), (118, 1), (119, 1), (120, 1)], [(121, 1)], [(35, 1), (66, 1)], [(122, 1), (123, 1)], [(124, 1), (125, 1), (126, 1)], [(5, 1), (126, 1), (127, 1), (128, 1)], [(93, 1), (129, 1), (130, 1)], [(39, 1), (131, 1)], [(132, 1), (133, 1)], [(134, 1), (135, 1)], [(136, 1)], [(93, 1), (137, 1), (138, 1)], [(104, 1)], [(139, 1)], [(140, 1)], [(141, 1), (142, 1), (143, 1)], [(144, 1), (145, 2), (146, 2), (147, 1)], [(21, 1), (148, 1)], [(104, 1), (149, 1), (150, 1)], [(93, 1), (138, 1), (151, 1)], [(152, 1)], [(152, 2)], [(15, 1), (126, 1), (141, 1), (153, 1), (154, 1), (155, 1), (156, 1), (157, 1)], [(149, 1), (158, 1), (159, 1)], [(160, 1)], [(43, 1), (161, 1)], [(162, 1), (163, 1)], [(164, 1), (165, 1)], [(166, 1), (167, 1)], [(9, 1), (99, 1), (168, 1)], [(169, 1), (170, 1), (171, 1)], [(172, 1), (173, 2), (174, 1), (175, 1)], [(176, 1), (177, 1), (178, 1)], [(51, 1), (173, 1), (179, 1), (180, 1), (181, 1), (182, 1)], [(183, 1), (184, 1), (185, 1)], [(186, 1)], [(185, 1), (187, 1), (188, 1)], [(51, 1), (120, 1), (126, 1), (189, 1), (190, 1)], [(62, 1)], [(21, 1), (191, 1)], [(139, 1), (192, 1), (193, 1), (194, 1), (195, 1), (196, 1)], [(51, 1), (183, 1), (184, 1), (197, 1), (198, 1)], [(21, 1), (169, 2), (199, 1), (200, 1), (201, 1), (202, 1)], [(203, 1), (204, 1), (205, 1)], [(2, 1), (51, 1)], [(39, 1), (149, 1), (151, 1), (156, 1)], [(206, 1), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (212, 1), (213, 1), (214, 1), (215, 1), (216, 1), (217, 1), (218, 1)], [(150, 1), (207, 2), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 2), (225, 1), (226, 1)], [(206, 1), (227, 1), (228, 1), (229, 1)], [(230, 1), (231, 1), (232, 1)], [(51, 1), (216, 1), (230, 1), (232, 1), (233, 1), (234, 1), (235, 1)], [(38, 1), (101, 1), (236, 1), (237, 1), (238, 1), (239, 1), (240, 1)], [(241, 1)], [(93, 1), (242, 1), (243, 1)], [(24, 1), (51, 1), (90, 1), (244, 1)], [(104, 1), (146, 1)], [(245, 1), (246, 1), (247, 1)], [(248, 1), (249, 1)], [(201, 1), (250, 1), (251, 1), (252, 1)], [(51, 1), (64, 1), (253, 1), (254, 1)], [(64, 1), (255, 1)], [(193, 1), (256, 1), (257, 1), (258, 2)], [(21, 1), (39, 1), (104, 1), (172, 1), (259, 1), (260, 1), (261, 1), (262, 1)], [(193, 1), (263, 1), (264, 1), (265, 1), (266, 1)], [(244, 1)], [(267, 1), (268, 1)], [(2, 1), (51, 1), (269, 1), (270, 1), (271, 1), (272, 1)], [(273, 1), (274, 1)], [(62, 1), (102, 1), (138, 1), (140, 1), (197, 1), (275, 1), (276, 1)], [(277, 1)], [(278, 1)], [(279, 1), (280, 1), (281, 1)], [(282, 1), (283, 1)], [(120, 1)], [(34, 1), (101, 1), (211, 1), (284, 1), (285, 1)], [(286, 1)], [(287, 1)], [(231, 1)], [(286, 1)], [(288, 1)], [(21, 1), (289, 1), (290, 1)], [(93, 1), (291, 1)], [(292, 1)], [(146, 1), (293, 1), (294, 1)], [(112, 1), (288, 1)], [(295, 1), (296, 1), (297, 1), (298, 1), (299, 1), (300, 1), (301, 1)], [(2, 1), (21, 1), (140, 1), (192, 1), (302, 1)], [(67, 1), (246, 1), (303, 1), (304, 1), (305, 1), (306, 1)], [(21, 1), (307, 1)], [(41, 1), (86, 1)], [(308, 1), (309, 1), (310, 1)], [(104, 1)], [(311, 1)], [(188, 1), (280, 1), (312, 1), (313, 1), (314, 1), (315, 1), (316, 1), (317, 1), (318, 1), (319, 1)], [(62, 1), (283, 1), (320, 1), (321, 1), (322, 1)], [(40, 1), (101, 1), (246, 1), (283, 1), (323, 1), (324, 1), (325, 1)], [(168, 1), (326, 1)], [(43, 1)], [(327, 1)], [(56, 1), (327, 1)], [(37, 1)], [(9, 1), (328, 1)], [(329, 1)], [(51, 1), (62, 1), (81, 1), (330, 1)], [(83, 1), (206, 1), (299, 1), (331, 1), (332, 1), (333, 1)], [(334, 1)], [(21, 1), (335, 1)], [(88, 1), (188, 1), (336, 1), (337, 1), (338, 1), (339, 1), (340, 1), (341, 1)], [(62, 1), (172, 1), (284, 1), (342, 1), (343, 1), (344, 1)], [(345, 1)], [(54, 1), (346, 1)], [(43, 1), (104, 1), (239, 1), (275, 1), (281, 1), (347, 1), (348, 1), (349, 1)], [(51, 1), (350, 1), (351, 1), (352, 1), (353, 1), (354, 1)], [(2, 1), (229, 1), (355, 1)], [(104, 1)], [(233, 1)], [(356, 1)], [(257, 1), (348, 1)], [(21, 1), (38, 1), (51, 1), (184, 1), (357, 1), (358, 1), (359, 1)], [(360, 1)], [(51, 1)], [(40, 1), (361, 1), (362, 1), (363, 1)], [(143, 1), (364, 1)], [(365, 1)], [(366, 1)], [(51, 1), (62, 1), (184, 1), (367, 1), (368, 1), (369, 1)], [(201, 1), (235, 1)], [(112, 1), (370, 1)], [(51, 1), (99, 1), (172, 1)], [(120, 1), (263, 1), (371, 1), (372, 1)], [(373, 1), (374, 1), (375, 1), (376, 1), (377, 1), (378, 1)], [(26, 1)]]\n",
      "LDA Model for May:\n",
      "LdaModel<num_terms=379, num_topics=5, decay=0.5, chunksize=200>\n",
      "Dictionary for Clarkson:\n",
      "Dictionary<671 unique tokens: ['much', 'thank', 'amount', 'buy', 'car']...>\n",
      "Corpus for Clarkson:\n",
      "[[(0, 1), (1, 1)], [(2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)], [(15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1)], [(23, 1)], [(24, 1)], [(25, 1), (26, 1), (27, 1)], [(28, 1)], [(29, 1)], [(30, 1), (31, 1), (32, 1)], [(33, 1), (34, 1)], [(35, 1), (36, 1), (37, 1)], [(36, 1), (37, 1), (38, 1)], [(39, 1)], [(40, 1)], [(7, 1)], [(41, 1)], [(42, 1)], [(42, 1)], [(43, 1), (44, 1)], [(45, 2)], [(46, 1)], [(4, 1), (5, 1), (47, 1), (48, 1), (49, 1)], [(4, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1)], [(4, 1), (25, 1), (28, 1), (50, 2), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1)], [(66, 1)], [(48, 1), (67, 1), (68, 1)], [(69, 1), (70, 1)], [(66, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1)], [(20, 1), (77, 1), (78, 1), (79, 1), (80, 1)], [(4, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1)], [(88, 1)], [(4, 1), (7, 1), (83, 1), (84, 1)], [(24, 1), (83, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1)], [(94, 2), (95, 1)], [(96, 1), (97, 1)], [(4, 1), (6, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1)], [(103, 1), (104, 1)], [(4, 1), (83, 1), (105, 1)], [(28, 1), (104, 1), (106, 1), (107, 1)], [(106, 1), (108, 1)], [(16, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1)], [(16, 1), (114, 1)], [(39, 1)], [(16, 1), (115, 1)], [(19, 1), (116, 1)], [(117, 1), (118, 1), (119, 1)], [(26, 1), (120, 1)], [(121, 1)], [(108, 1), (122, 1)], [(7, 1), (64, 1)], [(36, 1), (123, 1)], [(36, 1), (124, 1)], [(125, 1)], [(7, 1), (126, 1), (127, 1)], [(4, 1), (94, 1), (119, 1), (128, 1), (129, 1)], [(4, 1), (130, 1), (131, 1), (132, 1), (133, 1)], [(134, 1)], [(135, 1), (136, 1)], [(44, 1)], [(4, 1), (137, 1), (138, 1), (139, 1)], [(140, 1)], [(141, 1), (142, 1)], [(143, 1), (144, 1)], [(143, 1), (144, 1)], [(50, 1), (145, 1), (146, 1), (147, 1)], [(140, 1), (148, 1)], [(100, 1), (149, 1), (150, 1), (151, 1)], [(56, 1), (58, 1), (152, 1), (153, 1)], [(23, 1), (50, 1), (154, 1), (155, 1), (156, 1)], [(157, 1), (158, 1), (159, 1), (160, 1), (161, 1)], [(5, 1), (135, 1), (158, 1), (162, 1), (163, 1)], [(164, 1), (165, 1)], [(133, 1), (166, 1), (167, 1), (168, 1)], [(169, 1), (170, 1), (171, 1), (172, 1), (173, 1)], [(4, 1), (50, 1), (81, 1)], [(174, 1), (175, 1), (176, 1)], [(4, 1), (94, 1), (174, 1), (177, 1)], [(174, 1), (175, 1), (178, 1)], [(50, 1), (179, 1), (180, 1)], [(181, 1), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1)], [(16, 1), (94, 1), (174, 1), (182, 1), (187, 1), (188, 1), (189, 1)], [(0, 1), (20, 1), (189, 1), (190, 1), (191, 1), (192, 1), (193, 1), (194, 1), (195, 1)], [(18, 1)], [(44, 1)], [(196, 1), (197, 1), (198, 1)], [(199, 1)], [(200, 1)], [(201, 1), (202, 1), (203, 1)], [(38, 1), (44, 1), (204, 1), (205, 1), (206, 1)], [(141, 1)], [(187, 1)], [(135, 1), (207, 1)], [(14, 1), (208, 1)], [(209, 1), (210, 1)], [(209, 1), (211, 1), (212, 1), (213, 1)], [(140, 1)], [(55, 1), (120, 1), (166, 1), (214, 1), (215, 1), (216, 1), (217, 1), (218, 1)], [(219, 1)], [(219, 1), (220, 1)], [(221, 1)], [(222, 1), (223, 1), (224, 1), (225, 1)], [(39, 1), (226, 1), (227, 1), (228, 1)], [(31, 1), (38, 1), (50, 1), (59, 1), (135, 1), (189, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1)], [(19, 1), (39, 1), (189, 1), (234, 1), (235, 1), (236, 1)], [(237, 1), (238, 1)], [(28, 1), (118, 1), (220, 1)], [(239, 1)], [(240, 1)], [(93, 1), (241, 1), (242, 1)], [(13, 1)], [(136, 1), (243, 1), (244, 1)], [(218, 1), (245, 1), (246, 1), (247, 1)], [(16, 1), (67, 1), (162, 1), (184, 1), (198, 1), (248, 1)], [(106, 1), (249, 1)], [(199, 1), (250, 1)], [(251, 1)], [(155, 1), (252, 1)], [(253, 1)], [(254, 1)], [(4, 1), (255, 1)], [(39, 1), (83, 1), (135, 1), (256, 1), (257, 1)], [(4, 1), (48, 1), (67, 1), (258, 1), (259, 1), (260, 1), (261, 1), (262, 1), (263, 1), (264, 1)], [(135, 1)], [(17, 1)], [(135, 1), (265, 1)], [(39, 1), (266, 1)], [(267, 1)], [(16, 1), (268, 1)], [(269, 1)], [(39, 1), (270, 1)], [(55, 1), (265, 1)], [(38, 1), (50, 1), (51, 1), (55, 1), (56, 1), (58, 1)], [(170, 1), (213, 1), (271, 1), (272, 1), (273, 1)], [(274, 1)], [(274, 1), (275, 1), (276, 1)], [(17, 1), (83, 1), (151, 1), (277, 1), (278, 1), (279, 1), (280, 1)], [(167, 1), (281, 1), (282, 1), (283, 1)], [(284, 1), (285, 1)], [(154, 1), (286, 1)], [(233, 1), (287, 1)], [(77, 1), (140, 1)], [(288, 1)], [(81, 1), (138, 1), (289, 1)], [(20, 1), (157, 1), (290, 1)], [(13, 1), (90, 1), (97, 1), (168, 1), (291, 1), (292, 1), (293, 1), (294, 1)], [(295, 1), (296, 1)], [(297, 1), (298, 1)], [(299, 1)], [(19, 1), (49, 1), (300, 1), (301, 1), (302, 1)], [(0, 1), (38, 1), (59, 1), (303, 1)], [(162, 1), (291, 1), (295, 1)], [(304, 1)], [(78, 1), (83, 1), (291, 1), (305, 1), (306, 1)], [(16, 1), (307, 1)], [(16, 1), (308, 1), (309, 1)], [(310, 1)], [(7, 1), (18, 1), (156, 1), (223, 1), (311, 1), (312, 1)], [(16, 1), (67, 1), (162, 1), (313, 1)], [(314, 1), (315, 1)], [(168, 1), (316, 1), (317, 1), (318, 1), (319, 1), (320, 1)], [(67, 1), (162, 1), (233, 1), (321, 1), (322, 1)], [(323, 1)], [(109, 1)], [(17, 1), (295, 1), (324, 1), (325, 1), (326, 1), (327, 1), (328, 1), (329, 1)], [(140, 1)], [(330, 1), (331, 1), (332, 1), (333, 1), (334, 1), (335, 1), (336, 1)], [(337, 1), (338, 1), (339, 1)], [(236, 1), (340, 1)], [(128, 1), (341, 1), (342, 1), (343, 1), (344, 1)], [(220, 1), (345, 1)], [(128, 1)], [(128, 1)], [(128, 1), (155, 1), (346, 1), (347, 1)], [(348, 1)], [(349, 1), (350, 1)], [(349, 1)], [(351, 1)], [(351, 1)], [(174, 1), (352, 1), (353, 1)], [(354, 1)], [(355, 1)], [(140, 1)], [(7, 1), (356, 1)], [(357, 1)], [(28, 1), (358, 1), (359, 1)], [(360, 1), (361, 1)], [(7, 1), (362, 1)], [(44, 1)], [(94, 1), (140, 1), (311, 1), (363, 1), (364, 1), (365, 1)], [(4, 1), (48, 1), (366, 1)], [(367, 1), (368, 1)], [(48, 1), (76, 1)], [(199, 1)], [(199, 1)], [(369, 1)], [(76, 1), (370, 1)], [(17, 1), (44, 1), (371, 1), (372, 1)], [(6, 1), (48, 1), (373, 1)], [(219, 1)], [(214, 1)], [(374, 1)], [(375, 1), (376, 1)], [(377, 1)], [(4, 1), (223, 1), (378, 1), (379, 1)], [(94, 1), (189, 1), (380, 1), (381, 1), (382, 1)], [(6, 1), (19, 1), (168, 1), (293, 1), (383, 1), (384, 1), (385, 1), (386, 1), (387, 1), (388, 1)], [(285, 1)], [(389, 1)], [(389, 1)], [(16, 1), (291, 1), (293, 1), (390, 1), (391, 1)], [(4, 1), (90, 1), (140, 1), (392, 1), (393, 1), (394, 1)], [(118, 1), (395, 1)], [(168, 1), (233, 1), (236, 1), (287, 1), (293, 1), (376, 1)], [(396, 1)], [(135, 1), (214, 1), (397, 1), (398, 1), (399, 1)], [(400, 1), (401, 1), (402, 1), (403, 1)], [(59, 1), (404, 1)], [(40, 1), (120, 1), (135, 1), (158, 1), (319, 1), (385, 1), (405, 1), (406, 1)], [(407, 1), (408, 1)], [(5, 1)], [(0, 1), (4, 1), (118, 1), (409, 1), (410, 1)], [(0, 1), (84, 1), (209, 1), (411, 1), (412, 1), (413, 1), (414, 1), (415, 1), (416, 1)], [(50, 1), (66, 1)], [(17, 1), (19, 1), (44, 1), (417, 1), (418, 1), (419, 1), (420, 1), (421, 1)], [(7, 1), (422, 1), (423, 1), (424, 2)], [(38, 1), (425, 1), (426, 1)], [(284, 1), (427, 1)], [(347, 1)], [(428, 1), (429, 1)], [(251, 1), (430, 1), (431, 1)], [(7, 1), (128, 1), (432, 1), (433, 1), (434, 1)], [(282, 1), (435, 1)], [(209, 1), (353, 1)], [(436, 1), (437, 1), (438, 1)], [(439, 1)], [(256, 1), (440, 1)], [(140, 1)], [(140, 2), (363, 1), (441, 1)], [(16, 1), (43, 1), (53, 1), (263, 1), (442, 1), (443, 1)], [(17, 1), (282, 1), (444, 1)], [(76, 1), (84, 1), (313, 1), (323, 1), (445, 1), (446, 1)], [(19, 1), (36, 1), (78, 1), (81, 1), (255, 1), (363, 1), (447, 1), (448, 1), (449, 1), (450, 1), (451, 1)], [(4, 1), (84, 1), (449, 1), (452, 1)], [(372, 1), (442, 1), (453, 1)], [(140, 1)], [(19, 1), (70, 1), (213, 1), (454, 1)], [(455, 1)], [(166, 1), (440, 1)], [(456, 1)], [(457, 1), (458, 1), (459, 1), (460, 1)], [(259, 1)], [(461, 1), (462, 1)], [(49, 1), (84, 1), (463, 1), (464, 1)], [(465, 1)], [(466, 1), (467, 1)], [(38, 1), (40, 1), (468, 1), (469, 1), (470, 1)], [(4, 1), (18, 1), (97, 1), (175, 1), (471, 1), (472, 1), (473, 1), (474, 1), (475, 1), (476, 1)], [(14, 1), (76, 1), (237, 1), (246, 1), (477, 1)], [(478, 3), (479, 1)], [(478, 2), (479, 1), (480, 1)], [(56, 1), (140, 1), (233, 1), (290, 1), (481, 1), (482, 1), (483, 1), (484, 1)], [(4, 1), (94, 1)], [(485, 1)], [(486, 1), (487, 1)], [(140, 1)], [(16, 1), (268, 1), (488, 1), (489, 1)], [(181, 1), (399, 1)], [(31, 1), (135, 1), (490, 1)], [(151, 1), (471, 1), (484, 1)], [(288, 1)], [(82, 1), (491, 1), (492, 1), (493, 1)], [(494, 1)], [(94, 1)], [(83, 1), (353, 1)], [(50, 1), (65, 1), (100, 1), (233, 1)], [(16, 1), (233, 1), (495, 1)], [(496, 1)], [(496, 1), (497, 1), (498, 1)], [(499, 1), (500, 1)], [(501, 1)], [(502, 1), (503, 1)], [(244, 1), (504, 1)], [(155, 1), (205, 1), (505, 1)], [(44, 1), (506, 2), (507, 2)], [(4, 1), (212, 1), (255, 1), (262, 1), (471, 1), (508, 1), (509, 1)], [(38, 1), (140, 1), (510, 1), (511, 1)], [(16, 1), (140, 1)], [(78, 1), (83, 1), (453, 1), (512, 1), (513, 1)], [(514, 1)], [(4, 1), (66, 1), (515, 1)], [(19, 1), (255, 1), (516, 1)], [(16, 1), (92, 1), (517, 1)], [(4, 1), (53, 1), (90, 1), (301, 1), (518, 1), (519, 1), (520, 1), (521, 1)], [(214, 1), (499, 1)], [(522, 1), (523, 1)], [(27, 1), (36, 1), (44, 1), (81, 1), (221, 1), (524, 1), (525, 1), (526, 1), (527, 1)], [(4, 1), (77, 1), (140, 1), (528, 1)], [(529, 1), (530, 1), (531, 1)], [(17, 1), (532, 1)], [(151, 1), (533, 1)], [(4, 1), (84, 1), (399, 1), (416, 1), (534, 1)], [(399, 1), (535, 1)], [(4, 1), (16, 1), (67, 1), (123, 1), (173, 1), (272, 1), (439, 1), (536, 1), (537, 1), (538, 1)], [(496, 1)], [(539, 1), (540, 1)], [(116, 1)], [(140, 1), (359, 1)], [(146, 1), (290, 1), (538, 1), (541, 1), (542, 1)], [(448, 1), (543, 1)], [(543, 1)], [(83, 1), (135, 1), (544, 1), (545, 1), (546, 1), (547, 1)], [(4, 1), (39, 1), (93, 1), (223, 1), (246, 1), (477, 1)], [(31, 1), (548, 1), (549, 1)], [(154, 1), (383, 1), (550, 1), (551, 1), (552, 1)], [(33, 1), (553, 1), (554, 1)], [(140, 1), (555, 1), (556, 1)], [(0, 1), (6, 1), (17, 1), (120, 1), (246, 1), (413, 1), (550, 1), (557, 1), (558, 1)], [(140, 1)], [(140, 1)], [(123, 1), (559, 1)], [(123, 1), (559, 1)], [(123, 1), (560, 1)], [(240, 1)], [(120, 1), (561, 1)], [(14, 1), (176, 1), (559, 1), (562, 1), (563, 1)], [(285, 1)], [(17, 1), (19, 1), (78, 1), (81, 1), (265, 1), (564, 1)], [(140, 1), (223, 1), (565, 1)], [(33, 1), (140, 1), (566, 1)], [(17, 1), (19, 1), (81, 1), (84, 1), (415, 1), (416, 1), (564, 1), (565, 1)], [(567, 1)], [(140, 1)], [(85, 1), (90, 1), (135, 1), (159, 1), (176, 1), (568, 1)], [(140, 1), (244, 1), (569, 1)], [(48, 1), (49, 1), (65, 1), (74, 1), (570, 1), (571, 1), (572, 1)], [(4, 1), (28, 1), (162, 1), (181, 1), (223, 1), (233, 1), (236, 1), (573, 1), (574, 1)], [(38, 1), (50, 1), (159, 1), (294, 1), (298, 1), (301, 1), (399, 1), (407, 1), (497, 1), (575, 1), (576, 1), (577, 1), (578, 1), (579, 1), (580, 1)], [(135, 1)], [(4, 1), (16, 1), (100, 1), (581, 1), (582, 1)], [(583, 1), (584, 1)], [(44, 1), (56, 1), (265, 1), (585, 1), (586, 1), (587, 1), (588, 1), (589, 1), (590, 1), (591, 1)], [(255, 1)], [(120, 1), (565, 1)], [(50, 1), (592, 1)], [(593, 1)], [(28, 1)], [(594, 1)], [(593, 1), (595, 1)], [(596, 1)], [(597, 1)], [(598, 1), (599, 1)], [(17, 1), (114, 1), (598, 1), (599, 1)], [(176, 1), (333, 1), (600, 1)], [(44, 1), (153, 1), (437, 1), (601, 1)], [(44, 1), (277, 1), (602, 1)], [(135, 1), (603, 1), (604, 1)], [(135, 1)], [(237, 1)], [(135, 1)], [(4, 1), (380, 1), (533, 1), (605, 1)], [(17, 1)], [(4, 1), (16, 1), (135, 1), (176, 1)], [(16, 1), (606, 1), (607, 1)], [(4, 1), (217, 1), (608, 1), (609, 1)], [(16, 1), (55, 2), (56, 1), (58, 1), (176, 1), (610, 1), (611, 1), (612, 1), (613, 1)], [(25, 1), (56, 1), (614, 1)], [(77, 1)], [(14, 1), (615, 1), (616, 1)], [(4, 1), (176, 1), (610, 1), (617, 1)], [(618, 1)], [(238, 1), (434, 1)], [(619, 1)], [(619, 2), (620, 1)], [(0, 1), (6, 1), (93, 1), (265, 1), (621, 1)], [(83, 1), (197, 1), (622, 1)], [(7, 1), (53, 1), (110, 1), (623, 1), (624, 1)], [(16, 1), (159, 1), (200, 1), (578, 1), (625, 1), (626, 1)], [(77, 1), (110, 1), (135, 1), (236, 1)], [(294, 1), (612, 1)], [(112, 1), (295, 1), (571, 1), (627, 1)], [(233, 1)], [(193, 1), (628, 1)], [(537, 1)], [(353, 1), (452, 1), (629, 1)], [(4, 1), (196, 1), (270, 1), (570, 1), (630, 1), (631, 1), (632, 1)], [(633, 1)], [(49, 1), (53, 1), (66, 1), (536, 1), (634, 1), (635, 1), (636, 1), (637, 1)], [(638, 1), (639, 1), (640, 1)], [(301, 1)], [(4, 1), (174, 1), (571, 1)], [(641, 1), (642, 1)], [(270, 1), (460, 1)], [(50, 1), (128, 1), (643, 1)], [(133, 1), (200, 1), (246, 1), (321, 1), (447, 1), (644, 1), (645, 1), (646, 1), (647, 1)], [(78, 1)], [(16, 1), (27, 1), (648, 1)], [(268, 1)], [(17, 1), (104, 1), (649, 1)], [(120, 1)], [(97, 1), (650, 1), (651, 1)], [(237, 1), (246, 1), (652, 1)], [(575, 1)], [(16, 1), (67, 1), (339, 1), (624, 1), (653, 1)], [(287, 1), (326, 1), (383, 1), (464, 1), (654, 1), (655, 1), (656, 1)], [(28, 1), (214, 1)], [(50, 1)], [(153, 1)], [(200, 1), (536, 1)], [(44, 1), (59, 1), (82, 1), (657, 1)], [(658, 1), (659, 1)], [(4, 1), (59, 1), (83, 1), (220, 1), (641, 1), (660, 1), (661, 1)], [(107, 2), (614, 1), (625, 1), (654, 1)], [(56, 1), (58, 1), (244, 1), (466, 1), (618, 1), (662, 1), (663, 1)], [(663, 1), (664, 1), (665, 1), (666, 1), (667, 1), (668, 1)], [(284, 1)], [(16, 2), (128, 1)], [(669, 1)], [(66, 1)], [(669, 1)], [(66, 1)], [(4, 1), (466, 1), (670, 1)]]\n",
      "LDA Model for Clarkson:\n",
      "LdaModel<num_terms=671, num_topics=5, decay=0.5, chunksize=200>\n",
      "Dictionary for Hammond:\n",
      "Dictionary<415 unique tokens: ['come', 'gear', 'humdinger', 'real', 'special']...>\n",
      "Corpus for Hammond:\n",
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)], [(7, 1), (8, 1), (9, 1), (10, 1), (11, 1)], [(12, 1), (13, 1)], [(14, 1), (15, 1), (16, 1)], [(7, 1), (14, 1), (17, 1), (18, 1), (19, 1)], [(14, 1), (20, 1), (21, 1)], [(20, 1), (22, 1), (23, 1), (24, 1)], [(25, 1)], [(26, 1), (27, 1), (28, 1), (29, 1)], [(30, 1), (31, 1)], [(32, 1)], [(8, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1)], [(39, 1), (40, 1)], [(8, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1)], [(46, 1), (47, 1), (48, 1), (49, 1)], [(16, 1), (48, 2), (49, 1)], [(50, 1), (51, 1)], [(52, 1), (53, 1)], [(0, 1), (54, 1)], [(51, 1), (55, 1)], [(51, 1), (55, 1)], [(8, 1), (56, 1), (57, 1)], [(58, 1), (59, 1)], [(5, 1), (8, 1), (60, 1), (61, 1)], [(62, 1), (63, 1)], [(64, 1)], [(65, 1)], [(20, 1), (59, 1), (66, 1)], [(67, 1)], [(68, 1), (69, 1), (70, 1), (71, 1)], [(8, 1), (72, 1), (73, 1)], [(74, 1)], [(59, 1), (75, 1)], [(8, 1), (75, 1)], [(58, 1), (76, 2)], [(38, 1), (59, 1), (77, 1)], [(9, 1), (61, 1)], [(8, 1), (9, 1), (61, 1)], [(0, 1), (59, 1)], [(78, 2)], [(62, 1), (79, 1)], [(80, 1), (81, 1)], [(82, 1), (83, 1)], [(54, 1), (73, 1), (84, 1), (85, 1), (86, 1)], [(76, 1)], [(49, 1), (54, 1)], [(87, 1), (88, 1)], [(87, 1), (89, 1)], [(90, 1)], [(91, 1), (92, 1)], [(93, 1), (94, 1), (95, 1)], [(0, 1), (38, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1)], [(106, 1)], [(16, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1)], [(112, 1), (113, 1), (114, 1)], [(8, 1), (64, 1), (115, 1)], [(38, 1), (116, 1), (117, 1)], [(54, 1)], [(54, 1)], [(118, 1)], [(119, 1), (120, 1)], [(81, 1), (121, 1), (122, 1), (123, 1), (124, 1)], [(16, 1), (125, 1), (126, 1), (127, 1)], [(128, 1)], [(129, 1)], [(8, 1), (130, 1)], [(48, 1), (72, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1)], [(136, 1), (137, 1), (138, 1)], [(139, 1)], [(140, 1)], [(141, 1)], [(142, 1)], [(143, 1), (144, 1), (145, 1), (146, 1)], [(147, 1)], [(148, 1)], [(149, 3)], [(149, 1)], [(150, 1)], [(38, 1), (151, 1)], [(64, 1)], [(0, 1), (72, 1), (118, 1), (152, 1)], [(153, 1)], [(154, 1)], [(155, 1)], [(117, 1), (156, 1)], [(29, 1), (136, 1), (157, 1)], [(158, 1), (159, 1)], [(30, 1), (160, 1), (161, 1), (162, 1), (163, 1), (164, 1), (165, 1)], [(166, 1)], [(16, 1)], [(167, 1), (168, 1)], [(169, 1)], [(14, 1), (20, 1), (52, 1), (169, 1), (170, 2), (171, 1), (172, 1), (173, 1)], [(174, 1)], [(175, 1)], [(20, 1), (176, 1), (177, 1)], [(13, 1), (62, 1), (178, 1)], [(179, 1)], [(117, 1), (169, 1)], [(180, 1)], [(20, 1), (62, 1), (169, 1), (181, 1)], [(64, 1), (182, 1)], [(8, 1), (183, 1)], [(184, 1), (185, 1)], [(72, 1), (186, 1), (187, 1)], [(64, 1), (176, 1), (188, 1), (189, 1), (190, 1)], [(157, 1), (191, 1)], [(137, 1), (192, 1)], [(137, 1)], [(137, 1), (192, 1)], [(137, 1), (192, 1)], [(29, 1), (137, 1), (193, 1), (194, 1)], [(195, 1)], [(196, 1), (197, 1), (198, 1), (199, 1), (200, 1)], [(103, 1)], [(103, 1), (201, 1), (202, 1)], [(103, 1), (202, 1)], [(192, 1), (203, 1), (204, 1)], [(205, 1)], [(38, 1), (60, 1), (91, 1)], [(206, 1), (207, 1)], [(20, 1), (208, 1)], [(8, 1), (209, 1), (210, 1), (211, 1), (212, 1)], [(20, 1), (80, 1), (213, 1), (214, 1)], [(62, 1)], [(62, 1), (215, 1), (216, 1)], [(64, 1), (107, 1), (217, 1), (218, 1)], [(176, 1), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1)], [(116, 1), (227, 1), (228, 1), (229, 1)], [(222, 1), (230, 1)], [(25, 1), (64, 1), (231, 1)], [(232, 1)], [(0, 1), (226, 1), (233, 1), (234, 1)], [(235, 1)], [(236, 1), (237, 1)], [(38, 1), (238, 1), (239, 1), (240, 1), (241, 1)], [(80, 1), (242, 1)], [(103, 1)], [(72, 1)], [(12, 1), (243, 1), (244, 1)], [(82, 1), (202, 1)], [(190, 1)], [(244, 1), (245, 1)], [(213, 1)], [(246, 1)], [(247, 1), (248, 1), (249, 1)], [(250, 1), (251, 1)], [(252, 1)], [(253, 1), (254, 1)], [(125, 1), (220, 1), (222, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1)], [(54, 1), (157, 1), (259, 1), (260, 1)], [(20, 2), (149, 1), (241, 1), (254, 1), (261, 1), (262, 1)], [(126, 1), (263, 1), (264, 1)], [(220, 1), (254, 1), (265, 1), (266, 1), (267, 1), (268, 1), (269, 1), (270, 1)], [(64, 1), (176, 1), (271, 1)], [(272, 1)], [(273, 1)], [(274, 1), (275, 1), (276, 1)], [(62, 1)], [(8, 1), (20, 1), (156, 1), (249, 1), (277, 1), (278, 1)], [(91, 1)], [(32, 1)], [(13, 1), (279, 1), (280, 1), (281, 1), (282, 1)], [(59, 1), (225, 1), (283, 1), (284, 1)], [(162, 1), (285, 1)], [(227, 1), (242, 1), (286, 1), (287, 1), (288, 1)], [(162, 2), (180, 1), (213, 1), (278, 1)], [(20, 1), (77, 2), (162, 2), (174, 1), (282, 1), (285, 1), (289, 1), (290, 1), (291, 1), (292, 1)], [(13, 1), (293, 1), (294, 1)], [(295, 1)], [(296, 1), (297, 1)], [(42, 1)], [(298, 1), (299, 1)], [(58, 1), (300, 1), (301, 1)], [(153, 1), (302, 1), (303, 1), (304, 1), (305, 1)], [(0, 1), (304, 1)], [(86, 1)], [(190, 1), (306, 1), (307, 1)], [(16, 1), (64, 1), (308, 1), (309, 1), (310, 1), (311, 1), (312, 1), (313, 1)], [(157, 1), (313, 1), (314, 1), (315, 1), (316, 1), (317, 1), (318, 1)], [(299, 1)], [(20, 1), (31, 1)], [(38, 1), (319, 1)], [(299, 1), (320, 1)], [(321, 1), (322, 1)], [(33, 1), (176, 1), (304, 1), (323, 1), (324, 1), (325, 1), (326, 1), (327, 1)], [(299, 1), (304, 1), (328, 1), (329, 1), (330, 1)], [(304, 1), (331, 1)], [(54, 1), (203, 1), (332, 1)], [(8, 1), (323, 1), (333, 1)], [(299, 1), (334, 1), (335, 1)], [(13, 1), (322, 1), (336, 1), (337, 1)], [(8, 1), (338, 1)], [(92, 1)], [(46, 1), (339, 1)], [(94, 1), (340, 1)], [(32, 1), (341, 1), (342, 1)], [(245, 1)], [(216, 1), (319, 1)], [(337, 1), (343, 1), (344, 1), (345, 1), (346, 1)], [(96, 1)], [(72, 1)], [(72, 1)], [(37, 1), (190, 1), (347, 1)], [(348, 1)], [(32, 1), (72, 1)], [(8, 1), (114, 1), (349, 1), (350, 1), (351, 1)], [(321, 1), (322, 1)], [(49, 1), (352, 1)], [(38, 1), (79, 1)], [(92, 1)], [(353, 1)], [(92, 1)], [(354, 1)], [(29, 1), (355, 1), (356, 1), (357, 1)], [(60, 1), (358, 1), (359, 1)], [(355, 1), (360, 1)], [(321, 1)], [(78, 1)], [(361, 1), (362, 1)], [(362, 1)], [(13, 1), (20, 1)], [(331, 1)], [(363, 1)], [(30, 1), (38, 1), (364, 1), (365, 1)], [(366, 1), (367, 1), (368, 1)], [(20, 2), (176, 1), (369, 1)], [(176, 1), (370, 1), (371, 1), (372, 1)], [(30, 1), (64, 1), (93, 1), (373, 1), (374, 1), (375, 1)], [(376, 1)], [(377, 1)], [(163, 1), (173, 1), (281, 1), (285, 1), (378, 1), (379, 1), (380, 1)], [(283, 1), (372, 1), (380, 1), (381, 1), (382, 1), (383, 1)], [(20, 2), (93, 1), (149, 1), (177, 1), (213, 1), (285, 1), (384, 1), (385, 1), (386, 1), (387, 1)], [(0, 1)], [(0, 2)], [(388, 1)], [(389, 1), (390, 1)], [(0, 1)], [(0, 1)], [(391, 1)], [(391, 1)], [(391, 1)], [(59, 1)], [(20, 1), (30, 1), (369, 1)], [(240, 1)], [(83, 1), (392, 1)], [(51, 1), (52, 1), (218, 1), (250, 1), (393, 1), (394, 1), (395, 1)], [(396, 1), (397, 1)], [(248, 1)], [(337, 1)], [(345, 1)], [(216, 1), (240, 1), (398, 1)], [(178, 1)], [(20, 1), (46, 1)], [(120, 1), (270, 1), (399, 1), (400, 1), (401, 1), (402, 1), (403, 1)], [(285, 1), (404, 1)], [(202, 1), (341, 1), (405, 1), (406, 1), (407, 1)], [(222, 1)], [(408, 1)], [(156, 1), (237, 2)], [(54, 1), (409, 1), (410, 1)], [(54, 1), (411, 1)], [(20, 1), (46, 1)], [(139, 1)], [(8, 1), (139, 1), (157, 1), (250, 1)], [(213, 1)], [(137, 1)], [(308, 1), (412, 1)], [(413, 1)], [(268, 1), (414, 1)], [(410, 1)], [(143, 1)]]\n",
      "LDA Model for Hammond:\n",
      "LdaModel<num_terms=415, num_topics=5, decay=0.5, chunksize=200>\n"
     ]
    }
   ],
   "source": [
    "def create_corpora_and_LDA(data_sets, names, num_topics = 5):\n",
    "    results_dict = {}\n",
    "    for data, name in zip(data_sets, names):\n",
    "        # STEP 1 - Create dictionary\n",
    "        id2word = corpora.Dictionary(data)\n",
    "        print(f\"Dictionary for {name}:\")\n",
    "        print(id2word)\n",
    "\n",
    "        # STEP 2 - Create Corpus\n",
    "        texts = data\n",
    "\n",
    "        # STEP 3 - Term Document Frequency\n",
    "        corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "        print(f\"Corpus for {name}:\")\n",
    "        print(corpus)\n",
    "\n",
    "        # STEP 4- Create LDA Model\n",
    "        lda_model = gensim.models.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=num_topics,\n",
    "                                           random_state=100,\n",
    "                                           chunksize=200,\n",
    "                                           passes=10,\n",
    "                                           per_word_topics=True)\n",
    "\n",
    "        print(f\"LDA Model for {name}:\")\n",
    "        print(lda_model)\n",
    "\n",
    "        # STEP 5 - Store in dictionary\n",
    "        results_dict[name] = {\n",
    "            'dictionary': id2word,\n",
    "            'corpus': corpus,\n",
    "            'lda_model': lda_model\n",
    "        }\n",
    "\n",
    "    return results_dict\n",
    "\n",
    "# RESULTS_DICTIONARY - Create a dictionary of the data sets, their respective names, and the info created from the above function. \n",
    "\n",
    "data_sets = [May_cleaned_texts, Clarkson_cleaned_texts, Hammond_cleaned_texts]\n",
    "names = ['May', 'Clarkson', 'Hammond']\n",
    "results_dict = create_corpora_and_LDA(data_sets, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for May:\n",
      "[(0,\n",
      "  '0.018*\"next\" + 0.018*\"car\" + 0.018*\"hang\" + 0.013*\"drive\" + 0.013*\"good\" + '\n",
      "  '0.013*\"mercede\" + 0.013*\"smell\" + 0.013*\"probably\" + 0.013*\"delighted\" + '\n",
      "  '0.013*\"ruin\"'),\n",
      " (1,\n",
      "  '0.022*\"look\" + 0.017*\"water\" + 0.017*\"point\" + 0.012*\"mean\" + 0.012*\"soon\" '\n",
      "  '+ 0.012*\"gay\" + 0.012*\"brilliantly\" + 0.012*\"rougher\" + 0.012*\"near\" + '\n",
      "  '0.012*\"car\"'),\n",
      " (2,\n",
      "  '0.023*\"see\" + 0.023*\"get\" + 0.023*\"work\" + 0.017*\"car\" + 0.012*\"leave\" + '\n",
      "  '0.012*\"think\" + 0.012*\"bit\" + 0.012*\"long\" + 0.012*\"even\" + 0.012*\"pull\"'),\n",
      " (3,\n",
      "  '0.038*\"car\" + 0.038*\"know\" + 0.017*\"need\" + 0.017*\"cow\" + 0.017*\"hammond\" + '\n",
      "  '0.012*\"work\" + 0.012*\"want\" + 0.012*\"badger\" + 0.012*\"honey\" + '\n",
      "  '0.012*\"stopwatch\"'),\n",
      " (4,\n",
      "  '0.038*\"get\" + 0.033*\"come\" + 0.020*\"really\" + 0.015*\"work\" + 0.015*\"black\" '\n",
      "  '+ 0.015*\"take\" + 0.015*\"engine\" + 0.010*\"lift\" + 0.010*\"right\" + '\n",
      "  '0.010*\"snake\"')]\n",
      "Results for Clarkson:\n",
      "[(0,\n",
      "  '0.084*\"get\" + 0.046*\"true\" + 0.039*\"look\" + 0.032*\"beetle\" + 0.031*\"even\" + '\n",
      "  '0.027*\"brake\" + 0.023*\"simple\" + 0.023*\"easy\" + 0.023*\"comfortable\" + '\n",
      "  '0.023*\"surprisingly\"'),\n",
      " (1,\n",
      "  '0.051*\"right\" + 0.033*\"say\" + 0.030*\"crew\" + 0.027*\"car\" + 0.026*\"help\" + '\n",
      "  '0.025*\"back\" + 0.025*\"lancia\" + 0.024*\"put\" + 0.024*\"fix\" + 0.022*\"stay\"'),\n",
      " (2,\n",
      "  '0.049*\"think\" + 0.046*\"top\" + 0.041*\"drive\" + 0.032*\"people\" + 0.031*\"make\" '\n",
      "  '+ 0.031*\"car\" + 0.026*\"come\" + 0.024*\"actually\" + 0.024*\"tip\" + '\n",
      "  '0.023*\"honestly\"'),\n",
      " (3,\n",
      "  '0.045*\"gear\" + 0.035*\"mile\" + 0.031*\"away\" + 0.029*\"work\" + 0.029*\"want\" + '\n",
      "  '0.028*\"absolutely\" + 0.028*\"third\" + 0.026*\"carburettor\" + 0.026*\"bring\" + '\n",
      "  '0.026*\"engine\"'),\n",
      " (4,\n",
      "  '0.052*\"replace\" + 0.044*\"car\" + 0.028*\"watch\" + 0.027*\"brilliant\" + '\n",
      "  '0.026*\"starter\" + 0.025*\"electric\" + 0.025*\"offroad\" + 0.025*\"simple\" + '\n",
      "  '0.015*\"surrey\" + 0.011*\"well\"')]\n",
      "Results for Hammond:\n",
      "[(0,\n",
      "  '0.105*\"get\" + 0.027*\"drive\" + 0.027*\"engine\" + 0.022*\"man\" + 0.022*\"wait\" + '\n",
      "  '0.020*\"water\" + 0.017*\"jeremy\" + 0.017*\"start\" + 0.015*\"leave\" + '\n",
      "  '0.013*\"back\"'),\n",
      " (1,\n",
      "  '0.039*\"float\" + 0.029*\"second\" + 0.023*\"mile\" + 0.023*\"sorry\" + '\n",
      "  '0.017*\"need\" + 0.017*\"fix\" + 0.017*\"whole\" + 0.016*\"pull\" + 0.014*\"lion\" + '\n",
      "  '0.014*\"rifle\"'),\n",
      " (2,\n",
      "  '0.063*\"come\" + 0.053*\"car\" + 0.035*\"really\" + 0.024*\"oliver\" + 0.021*\"cow\" '\n",
      "  '+ 0.021*\"good\" + 0.021*\"arrive\" + 0.017*\"see\" + 0.017*\"want\" + '\n",
      "  '0.015*\"ever\"'),\n",
      " (3,\n",
      "  '0.044*\"look\" + 0.036*\"bit\" + 0.028*\"think\" + 0.027*\"use\" + 0.026*\"beetle\" + '\n",
      "  '0.024*\"enough\" + 0.021*\"proper\" + 0.019*\"say\" + 0.016*\"light\" + '\n",
      "  '0.016*\"hang\"'),\n",
      " (4,\n",
      "  '0.026*\"thank\" + 0.026*\"brake\" + 0.024*\"know\" + 0.019*\"work\" + 0.019*\"truck\" '\n",
      "  '+ 0.014*\"straight\" + 0.014*\"stop\" + 0.014*\"almost\" + 0.014*\"possible\" + '\n",
      "  '0.014*\"local\"')]\n"
     ]
    }
   ],
   "source": [
    "#Print the keyword in the 5 topics\n",
    "# \n",
    "import pprint\n",
    "\n",
    "for name, result in results_dict.items():\n",
    "    print(f\"Results for {name}:\")\n",
    "    pprint.pprint(result['lda_model'].print_topics())\n",
    "\n",
    "\n",
    "# print(lda_model.print_topics())\n",
    "# doc_lda = lda_model[corpus]\n",
    "\n",
    "#We created 5 topics. You can see the keywords for each topic and the weightage(importance) of each keyword using lda_model.print_topics() as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize LDA Topic Models for each Presenter\n",
    "\n",
    "### Create a Visualize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "def visualize_lda_model(results_dict, dataset_name):\n",
    "    # Access the dictionary, corpus, and LDA model for the specified dataset\n",
    "    dictionary = results_dict[dataset_name]['dictionary']\n",
    "    corpus = results_dict[dataset_name]['corpus']\n",
    "    lda_model = results_dict[dataset_name]['lda_model']\n",
    "\n",
    "    # Prepare the visualization\n",
    "    vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary, mds='mmds', R=30)\n",
    "\n",
    "    # Display the visualization\n",
    "    return vis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the LDA Visualization for a given Presenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1542418579891507525014665707\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1542418579891507525014665707_data = {\"mdsDat\": {\"x\": [-0.06418744697195754, -0.08119629682752966, -0.17864441728129288, 0.14988255947544324, 0.17414560160533676], \"y\": [0.18042070207090727, -0.1940765393118472, 0.0045362980704467554, -0.12381133920291376, 0.13293087837340695], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [24.76914534487687, 21.362234125355858, 18.774904892900334, 17.99713516226678, 17.096580474600152]}, \"tinfo\": {\"Term\": [\"get\", \"right\", \"replace\", \"think\", \"top\", \"true\", \"drive\", \"gear\", \"look\", \"car\", \"mile\", \"people\", \"beetle\", \"crew\", \"away\", \"even\", \"say\", \"work\", \"simple\", \"want\", \"watch\", \"make\", \"absolutely\", \"third\", \"help\", \"brilliant\", \"come\", \"carburettor\", \"bring\", \"starter\", \"right\", \"crew\", \"help\", \"lancia\", \"back\", \"stay\", \"put\", \"realistically\", \"fix\", \"water\", \"give\", \"say\", \"die\", \"time\", \"pan\", \"hard\", \"feel\", \"stick\", \"morning\", \"head\", \"run\", \"world\", \"hell\", \"tell\", \"film\", \"drain\", \"happen\", \"know\", \"quite\", \"try\", \"rally\", \"dust\", \"salt\", \"car\", \"bonnet\", \"get\", \"use\", \"break\", \"day\", \"think\", \"top\", \"drive\", \"people\", \"come\", \"actually\", \"tip\", \"magnanimous\", \"unmodified\", \"honestly\", \"make\", \"leave\", \"unfortunately\", \"sad\", \"bit\", \"boy\", \"long\", \"cover\", \"need\", \"whole\", \"botswana\", \"man\", \"let\", \"power\", \"obviously\", \"struggle\", \"wait\", \"way\", \"soon\", \"fourwheel\", \"surrey\", \"stop\", \"car\", \"take\", \"day\", \"gear\", \"bad\", \"replace\", \"watch\", \"brilliant\", \"electric\", \"offroad\", \"starter\", \"well\", \"diesel\", \"door\", \"hammond\", \"year\", \"move\", \"ready\", \"push\", \"zimbabwe\", \"twostroke\", \"ill\", \"slow\", \"oclock\", \"keep\", \"moon\", \"low\", \"first\", \"belt\", \"fan\", \"border\", \"front\", \"fine\", \"possible\", \"eventually\", \"much\", \"simple\", \"life\", \"car\", \"surrey\", \"really\", \"coupe\", \"still\", \"tyre\", \"turn\", \"mile\", \"away\", \"work\", \"absolutely\", \"third\", \"carburettor\", \"want\", \"engine\", \"bring\", \"square\", \"stall\", \"good\", \"gear\", \"open\", \"night\", \"last\", \"far\", \"elephant\", \"amazing\", \"ridiculous\", \"speed\", \"half\", \"metre\", \"mechanic\", \"combover\", \"entire\", \"mate\", \"team\", \"guide\", \"distributor\", \"ever\", \"see\", \"stop\", \"mouth\", \"say\", \"true\", \"look\", \"beetle\", \"even\", \"brake\", \"comfortable\", \"easy\", \"inexpensive\", \"maintain\", \"surprisingly\", \"model\", \"showroom\", \"motor\", \"get\", \"lose\", \"call\", \"wheel\", \"stig\", \"probably\", \"hold\", \"special\", \"camp\", \"tick\", \"wide\", \"jam\", \"ground\", \"surface\", \"rough\", \"beater\", \"begin\", \"simple\", \"break\", \"rally\", \"way\", \"stage\", \"know\", \"make\", \"bad\", \"see\"], \"Freq\": [25.0, 17.0, 13.0, 14.0, 13.0, 10.0, 12.0, 12.0, 9.0, 28.0, 8.0, 9.0, 7.0, 10.0, 7.0, 7.0, 12.0, 7.0, 11.0, 7.0, 7.0, 10.0, 7.0, 7.0, 9.0, 7.0, 7.0, 6.0, 6.0, 7.0, 16.585247369173636, 9.675633683987046, 8.63199792086302, 8.107331550445904, 8.230506211755136, 7.217634492833913, 7.697928114933946, 7.21444331035375, 7.679941560520813, 3.6562499328471576, 3.1926714353545185, 10.779858166111815, 2.5194141116728024, 2.452360088563116, 2.086714193397723, 1.7805643774967905, 1.7202474133254946, 1.5687698435019395, 1.5616654826196694, 1.5452050996830307, 1.4153035569499814, 1.414677260045673, 1.5225978017500925, 1.2611518071963035, 1.1927038443479838, 1.1898861158914065, 1.1897531246375326, 3.239443646659827, 1.0466003060259137, 1.0465513931946775, 2.465549084128621, 1.4170958628374262, 1.6403902287849008, 8.902390482388578, 1.7848038439780767, 5.797973288711025, 1.571342931850734, 1.6544874535987344, 1.4686767219241528, 13.905008319477469, 12.809315612280395, 11.498877476881663, 9.090638954468812, 7.421239678951281, 6.770756864406181, 6.766842302438669, 6.313411829654923, 6.313411829654923, 6.52774693630095, 8.848118477618957, 2.2816011326695, 1.6902761532876367, 1.5074775072258562, 2.9619973318880213, 1.3720820056320997, 1.3720547556692737, 1.371942480582053, 2.018916600394426, 1.347313754564772, 1.2341341781932613, 1.7006306151237882, 0.9152257015843156, 0.9150293839434751, 0.9145183161310501, 0.9143861276094564, 0.905587599347841, 2.5777144258319913, 0.8937352411175952, 0.7806846435364797, 4.120398492000792, 1.826858207349256, 8.750823533424045, 1.2300900478928898, 1.002796208323991, 1.1071701819243067, 0.9157293018588508, 12.850659939823588, 7.040097816567422, 6.717658850423225, 6.2663423987794955, 6.261593943950907, 6.519755135818916, 2.82141165093109, 2.4041279415423467, 2.267612628627693, 2.1351710385994473, 1.8140650710379513, 1.4962123246870989, 1.4139484536149802, 1.3623950184054106, 1.3594384029085993, 1.042412606183812, 1.042387505234427, 1.0423869295245787, 1.0422997670535497, 1.0422997670535497, 1.0422389720935714, 1.0417932575290354, 1.0416390824316668, 1.0414774231062707, 1.0414774231062707, 1.0392251310378413, 1.0312014628824049, 1.0549009042126365, 0.9086535041677843, 1.3638263482301969, 2.120332002118138, 6.259224782783278, 1.8028850160683512, 10.902747971017748, 3.7234704563578456, 1.6978209624490095, 1.2126949136874867, 1.3576969957595308, 1.2306131918632905, 1.2283991269287868, 8.18634686679064, 7.292074624740136, 6.988671889190829, 6.5706331636305615, 6.567484468497894, 6.271823231707887, 6.92924048930592, 6.145311645738763, 6.259681859744414, 5.845779880313297, 5.845779880313297, 5.427836957731689, 10.669828498541527, 2.1067456894343115, 1.689057836764775, 1.6829501761311372, 1.5653573176890163, 1.3944270338558173, 1.2715876378670283, 1.2692171763778144, 1.1457241568410845, 0.9728820075743442, 0.9728820075743442, 0.9720708830465128, 0.970293781941245, 0.954265877388505, 0.848040792894403, 0.8478353904251835, 0.8474967136509761, 0.8473301621592769, 1.9923525180328536, 2.059359196301647, 1.2738100903765415, 0.9735285673081905, 1.568700046965095, 10.332659000185108, 8.783822272657002, 7.312224183735868, 6.931921838728719, 5.972002994030181, 5.2225102233163625, 5.2225102233163625, 5.2225102233163625, 5.2225102233163625, 5.2225102233163625, 5.222448571980745, 5.222448571980745, 5.213878197536312, 18.943563116532406, 1.4007436138760274, 1.0236910701400468, 1.0228211362427448, 0.8687633082943331, 0.8681002943134256, 0.8681002943134256, 0.8617529328243492, 0.7572786109426842, 0.7572238796549426, 0.7569534735417521, 0.7569534735417521, 0.7563879169017561, 0.7527021001898355, 0.7322919956520931, 0.7321671202427058, 0.7211437461002697, 5.22449522856449, 1.7585859998607756, 1.2356456359115424, 1.1600113999195514, 0.862693010843297, 1.1475630725854458, 1.3947442469157139, 0.9160298040887491, 0.8326270804121856], \"Total\": [25.0, 17.0, 13.0, 14.0, 13.0, 10.0, 12.0, 12.0, 9.0, 28.0, 8.0, 9.0, 7.0, 10.0, 7.0, 7.0, 12.0, 7.0, 11.0, 7.0, 7.0, 10.0, 7.0, 7.0, 9.0, 7.0, 7.0, 6.0, 6.0, 7.0, 17.09446741385369, 10.18574982396597, 9.140479205172959, 8.617413419970632, 8.765197049819836, 7.7261261169339015, 8.240704104357919, 7.725697389513983, 8.233114919742555, 4.168337450939225, 3.7058886858433002, 12.73645387038, 3.029590609298971, 2.9678892945795514, 2.5991922838017256, 2.291784144153211, 2.2314769523623745, 2.077667968344836, 2.076775371198616, 2.074342060832257, 1.9237596139673931, 1.9236220326725744, 2.0715654438066338, 1.7696321456498831, 1.708008925212505, 1.7077032236935126, 1.7076761627700972, 4.785494100014895, 1.5550526713144632, 1.5550333629891577, 4.106762295990203, 2.1909850205202646, 2.6310488159149052, 28.797234131774417, 3.015027995656647, 25.140275402701576, 2.8520778717437922, 3.814261481548504, 2.844925755071089, 14.445514307289482, 13.341344819373264, 12.030281864967293, 9.637731858557073, 7.951727768361126, 7.29867747983724, 7.298347846855718, 6.841354750394624, 6.841354750394624, 7.753359279516651, 10.660455037296902, 2.8158971178596253, 2.223443259128483, 2.0354367848514636, 4.060203099322097, 1.900552672084067, 1.900617691067423, 1.900649329744071, 2.844663565013078, 1.9039144966796473, 1.7658068535581872, 2.6472767888907716, 1.4433229421280676, 1.4433614569345932, 1.4431978850280105, 1.4432508580940722, 1.4415931002318287, 4.155995384308428, 1.4433371797975858, 1.308570777332662, 8.239037726789192, 3.5038139127967276, 28.797234131774417, 2.990971071655927, 2.844925755071089, 12.180815755902058, 2.6107265828078434, 13.38090995789886, 7.5692757979368155, 7.2491034304889785, 6.795277816225322, 6.7951832481046335, 7.106210946820472, 3.358019694320419, 2.9330386163524116, 2.7990908269076837, 2.665361577794957, 2.3451954096686847, 2.02520338029474, 1.9438765676757772, 1.8914329870357995, 1.891608532436014, 1.5713283583442874, 1.5713212180228793, 1.5713211123928352, 1.5712967440688903, 1.571296773551221, 1.5712797238734262, 1.5712192446149287, 1.5714268840236318, 1.571249148580598, 1.571249148580598, 1.5716644757602105, 1.5705034408209613, 1.6212436348612296, 1.4375622703264015, 2.158485962633977, 3.443438942352346, 11.905051292715278, 2.9892346028150625, 28.797234131774417, 8.239037726789192, 3.0602314520151546, 2.021963196786468, 2.536970364568312, 2.4484865013167525, 2.6490291985238823, 8.727516622378731, 7.831114952596158, 7.53187316829037, 7.108636852160413, 7.108965627280999, 6.809876757735063, 7.536633903124089, 6.685441565308096, 6.8107573581576, 6.3868541895948345, 6.3868541895948345, 5.970071818009742, 12.180815755902058, 2.6557085412270793, 2.2342913129370503, 2.2340732240814387, 2.1086300736128, 1.9341624812529556, 1.8095416994474107, 1.8093707486046882, 1.6847629035211755, 1.5107800175029598, 1.5107800175029598, 1.5107503726701454, 1.5105826015604051, 1.514335504512249, 1.3859360924538722, 1.3859503322230182, 1.3859705397210795, 1.3860888749709805, 3.423273707983178, 4.936446373585342, 3.5038139127967276, 2.0332858414936488, 12.73645387038, 10.884160683937866, 9.341192367143321, 7.864577329466385, 7.486764278870885, 6.53148726159312, 5.773859521175238, 5.773859521175238, 5.773859521175238, 5.773859521175238, 5.773859521175238, 5.773852658951884, 5.773852658951884, 5.7767328043778345, 25.140275402701576, 1.9541233546024843, 1.5755218053416034, 1.575835420671912, 1.4201183511995277, 1.420248814982595, 1.420248823170685, 1.4209296592102594, 1.3086348385651352, 1.3086298003019818, 1.3087179261043396, 1.3087179261043396, 1.3089008868664678, 1.3095056547100574, 1.3140161549449727, 1.3167300219876186, 1.3156867569264388, 11.905051292715278, 3.814261481548504, 4.106762295990203, 4.155995384308428, 1.9432568249343758, 4.785494100014895, 10.660455037296902, 2.6107265828078434, 4.936446373585342], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.979, -3.5179, -3.6321, -3.6948, -3.6797, -3.811, -3.7466, -3.8115, -3.7489, -4.4911, -4.6267, -3.4099, -4.8635, -4.8905, -5.0519, -5.2106, -5.2451, -5.3372, -5.3418, -5.3524, -5.4402, -5.4406, -5.3671, -5.5555, -5.6113, -5.6137, -5.6138, -4.6121, -5.742, -5.742, -4.8851, -5.4389, -5.2926, -3.6012, -5.2082, -4.03, -5.3356, -5.284, -5.4032, -3.0073, -3.0894, -3.1973, -3.4323, -3.6352, -3.727, -3.7275, -3.7969, -3.7969, -3.7635, -3.4594, -4.8147, -5.1147, -5.2291, -4.5537, -5.3232, -5.3233, -5.3233, -4.937, -5.3415, -5.4292, -5.1086, -5.7282, -5.7284, -5.7289, -5.7291, -5.7387, -4.6927, -5.7519, -5.8872, -4.2236, -5.037, -3.4704, -5.4325, -5.6368, -5.5378, -5.7276, -2.9571, -3.5588, -3.6057, -3.6753, -3.676, -3.6356, -4.4732, -4.6333, -4.6917, -4.7519, -4.9149, -5.1075, -5.1641, -5.2012, -5.2034, -5.4689, -5.4689, -5.4689, -5.469, -5.469, -5.4691, -5.4695, -5.4697, -5.4698, -5.4698, -5.472, -5.4797, -5.457, -5.6063, -5.2002, -4.7589, -3.6764, -4.9211, -3.1214, -4.1958, -4.9811, -5.3176, -5.2047, -5.303, -5.3048, -3.3657, -3.4814, -3.5239, -3.5855, -3.586, -3.6321, -3.5324, -3.6525, -3.634, -3.7024, -3.7024, -3.7766, -3.1007, -4.723, -4.944, -4.9476, -5.02, -5.1357, -5.2279, -5.2298, -5.3321, -5.4956, -5.4956, -5.4965, -5.4983, -5.515, -5.633, -5.6332, -5.6336, -5.6338, -4.7788, -4.7458, -5.2261, -5.495, -5.0179, -3.0815, -3.2439, -3.4273, -3.4807, -3.6297, -3.7638, -3.7638, -3.7638, -3.7638, -3.7638, -3.7639, -3.7639, -3.7655, -2.4754, -5.0798, -5.3934, -5.3943, -5.5575, -5.5583, -5.5583, -5.5656, -5.6948, -5.6949, -5.6953, -5.6953, -5.696, -5.7009, -5.7284, -5.7286, -5.7437, -3.7635, -4.8523, -5.2052, -5.2684, -5.5645, -5.2792, -5.0841, -5.5045, -5.6], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.3653, 1.3442, 1.3383, 1.3346, 1.3326, 1.3275, 1.3274, 1.3271, 1.326, 1.2645, 1.2465, 1.2288, 1.2112, 1.2048, 1.176, 1.1432, 1.1354, 1.1146, 1.1105, 1.1011, 1.0886, 1.0883, 1.0877, 1.0568, 1.0365, 1.0343, 1.0342, 1.0054, 0.9996, 0.9996, 0.8854, 0.9598, 0.9231, 0.2216, 0.8713, -0.0714, 0.7995, 0.5603, 0.7344, 1.5054, 1.5029, 1.4984, 1.4851, 1.4745, 1.4685, 1.4679, 1.4632, 1.4632, 1.3715, 1.3572, 1.3331, 1.2694, 1.2433, 1.2282, 1.2177, 1.2177, 1.2176, 1.2007, 1.1977, 1.1853, 1.101, 1.088, 1.0878, 1.0873, 1.0871, 1.0786, 1.0659, 1.0642, 1.027, 0.8506, 0.8923, 0.3524, 0.655, 0.5008, -0.8545, 0.4959, 1.6322, 1.6002, 1.5965, 1.5916, 1.5909, 1.5865, 1.4985, 1.4738, 1.4621, 1.4509, 1.4159, 1.3699, 1.3544, 1.3446, 1.3423, 1.2623, 1.2622, 1.2622, 1.2622, 1.2622, 1.2621, 1.2617, 1.2615, 1.2614, 1.2614, 1.259, 1.252, 1.2429, 1.2139, 1.2135, 1.1878, 1.0297, 1.167, 0.7014, 0.8784, 1.0835, 1.1614, 1.0475, 0.9847, 0.9042, 1.6509, 1.6436, 1.6401, 1.6363, 1.6357, 1.6327, 1.6309, 1.6307, 1.6306, 1.6264, 1.6264, 1.6197, 1.5825, 1.4834, 1.4352, 1.4317, 1.417, 1.3878, 1.3622, 1.3604, 1.3294, 1.2748, 1.2748, 1.274, 1.2723, 1.2532, 1.2238, 1.2235, 1.2231, 1.2228, 1.1737, 0.8407, 0.7031, 0.9785, -0.3793, 1.7143, 1.7048, 1.6935, 1.6893, 1.6767, 1.6659, 1.6659, 1.6659, 1.6659, 1.6659, 1.6659, 1.6659, 1.6638, 1.4833, 1.4334, 1.3351, 1.3341, 1.2749, 1.274, 1.274, 1.2662, 1.2193, 1.2192, 1.2188, 1.2188, 1.2179, 1.2126, 1.1816, 1.1794, 1.165, 0.9427, 0.9921, 0.5653, 0.4902, 0.9542, 0.3383, -0.2675, 0.719, -0.0135]}, \"token.table\": {\"Topic\": [4, 2, 4, 4, 1, 1, 2, 5, 5, 5, 5, 3, 2, 4, 1, 4, 3, 2, 2, 5, 1, 5, 3, 4, 5, 5, 1, 2, 3, 4, 4, 2, 5, 3, 2, 1, 1, 2, 1, 3, 4, 3, 1, 2, 1, 5, 3, 4, 4, 4, 5, 3, 1, 4, 3, 4, 1, 1, 3, 3, 1, 2, 3, 2, 4, 1, 5, 1, 4, 5, 4, 4, 3, 1, 1, 1, 1, 1, 5, 2, 4, 3, 5, 5, 3, 1, 5, 1, 4, 2, 2, 3, 5, 2, 5, 5, 3, 2, 5, 2, 5, 2, 4, 4, 4, 4, 4, 5, 3, 1, 5, 1, 4, 3, 2, 3, 2, 4, 2, 3, 3, 4, 1, 2, 3, 2, 5, 3, 1, 1, 1, 5, 3, 1, 3, 4, 3, 4, 1, 5, 1, 2, 1, 5, 1, 4, 1, 3, 4, 5, 5, 3, 5, 3, 2, 5, 4, 4, 1, 5, 4, 3, 1, 1, 5, 3, 5, 2, 4, 2, 5, 5, 2, 3, 1, 2, 3, 4, 1, 2, 4, 5, 1, 2, 2, 5, 1, 1, 3, 3, 1, 3, 2, 2, 1, 3, 2, 4, 3, 1, 2, 5, 3, 5, 2, 5, 4, 1, 3, 3], \"Freq\": [0.9847176252747534, 0.959077862987871, 0.5526261153889823, 0.8938701631086863, 0.9127005308071695, 0.38303513151672025, 0.38303513151672025, 0.38303513151672025, 0.7594571273543903, 0.8900669046476212, 0.7600593338311689, 0.6364363034998994, 0.7388792941173038, 0.24629309803910127, 0.6633437576304884, 0.3316718788152442, 0.6362681191965621, 0.5663133530062765, 0.5261627392328156, 0.9186269159983812, 0.5243479005503433, 0.5243479005503433, 0.9656366566048327, 0.8809592949033027, 0.6347103522208509, 0.7641551107537832, 0.3125300144734921, 0.3125300144734921, 0.3819811288009348, 0.8810732137237055, 0.6619962383831361, 0.8803118270537473, 0.8659718827004431, 0.49456884358197656, 0.526135981188415, 0.9817637555235333, 0.3515030219039976, 0.3515030219039976, 0.990232802673686, 0.6818866921320123, 0.721454459419809, 0.7145177215308568, 0.5855818423983215, 0.9143592912841453, 0.4564157174212643, 0.8659718827004431, 0.8829661070918382, 0.5170196452948448, 0.8974725066979913, 0.6603556457735494, 0.9349833571968296, 0.4632877013384469, 0.2921180382590997, 0.5842360765181994, 0.6364363034998994, 0.948483105229226, 0.8962673792721366, 0.5854770342465179, 0.6168104401443618, 0.6363643196936432, 0.9716856958739204, 0.7641925200548645, 0.6367384967187734, 0.08209630783680993, 0.9030593862049092, 0.23866087001398717, 0.7557594217109594, 0.8095224261484609, 0.8375108629207183, 0.7639997879396491, 0.7215160577664556, 0.661909734319107, 0.7503672359735117, 0.5855911219009204, 0.8726825364868636, 0.9641611370487132, 0.965453447767922, 0.9846310896814408, 0.7041019740241815, 0.9028344679567569, 0.128976352565251, 0.6364071130269937, 0.8659718827004431, 0.7641065962752568, 0.6364170135345868, 0.6268945144014831, 0.2089648381338277, 0.9283528142516881, 0.8952258047953284, 0.7102532217228902, 0.6928456347583429, 0.6690675927933301, 0.33453379639666503, 0.5261447395232762, 0.9634744309148979, 0.5117384210391488, 0.6364484163666656, 0.8770192774543533, 0.8659718827004431, 0.844241635888187, 0.09380462620979856, 0.7554933463674627, 0.37774667318373134, 0.7215339909572943, 0.661922722701415, 0.661909734319107, 0.9166410499278496, 0.8659729119079461, 0.636423919182804, 0.9630314514206201, 0.8655411578342007, 0.4918147658301705, 0.4918147658301705, 0.49377756808526757, 0.2904073563496559, 0.5808147126993118, 0.7030708392367676, 0.8951384219325158, 0.6929056717544949, 0.6364170254757157, 0.8829783952733825, 0.7530946897794338, 0.7694698127814872, 0.9338296740440181, 0.6956220406180721, 0.6928271467937055, 0.7041019780835057, 0.5286996720762346, 0.9707908327601973, 0.6430650346748157, 0.48700164651671657, 0.24350082325835828, 0.5144359557745294, 0.9060670703334867, 0.6535453384360863, 0.32677266921804315, 0.9715333292655478, 0.5526783279607889, 0.9944738018701226, 0.761025651196714, 0.519815465892689, 0.982590083310276, 0.7601531328123731, 0.38007656640618653, 0.8636626891557068, 0.15702957984649213, 0.20257487356713647, 0.20257487356713647, 0.40514974713427293, 0.20257487356713647, 0.8659729119079461, 0.5039877487694161, 0.4199897906411801, 0.6364071558086447, 0.6928388002450269, 0.7037646047558691, 0.5935553293047867, 0.9394296193225956, 0.5146000194975618, 0.5146000194975618, 0.9394296193225956, 0.9850537863827427, 0.9060167921227174, 0.962617718746124, 0.7041666626977481, 0.3941709426196466, 0.3941709426196466, 0.5708065695770953, 0.28540328478854765, 0.6928802393511685, 0.7636469505902316, 0.8659718827004431, 0.4854935894994168, 0.4854935894994168, 0.33433957602483866, 0.33433957602483866, 0.33433957602483866, 0.7215265776487338, 0.5650891923828373, 0.9691589861176029, 0.984672084098587, 0.7641580527733957, 0.6738795829253906, 0.9591211801470586, 0.9744145118805723, 0.9187662963077481, 0.6430730193966728, 0.3774967828052744, 0.3774967828052744, 0.6364042211099038, 0.4084155658861986, 0.4084155658861986, 0.8995057516259418, 0.8770192774543533, 0.7012431251665572, 0.3506215625832786, 0.6936770159618451, 0.9287966073419536, 0.9247912464635012, 0.9596152056016256, 0.7218487323943962, 0.2406162441314654, 0.8933836823750751, 0.6345840351612451, 0.5252336708103021, 0.7641065962752568, 0.9293836796761811, 0.519852644134386, 0.8528074000803831, 0.5286506075927876], \"Term\": [\"absolutely\", \"actually\", \"amazing\", \"away\", \"back\", \"bad\", \"bad\", \"bad\", \"beater\", \"beetle\", \"begin\", \"belt\", \"bit\", \"bit\", \"bonnet\", \"bonnet\", \"border\", \"botswana\", \"boy\", \"brake\", \"break\", \"break\", \"brilliant\", \"bring\", \"call\", \"camp\", \"car\", \"car\", \"car\", \"carburettor\", \"combover\", \"come\", \"comfortable\", \"coupe\", \"cover\", \"crew\", \"day\", \"day\", \"die\", \"diesel\", \"distributor\", \"door\", \"drain\", \"drive\", \"dust\", \"easy\", \"electric\", \"elephant\", \"engine\", \"entire\", \"even\", \"eventually\", \"ever\", \"ever\", \"fan\", \"far\", \"feel\", \"film\", \"fine\", \"first\", \"fix\", \"fourwheel\", \"front\", \"gear\", \"gear\", \"get\", \"get\", \"give\", \"good\", \"ground\", \"guide\", \"half\", \"hammond\", \"happen\", \"hard\", \"head\", \"hell\", \"help\", \"hold\", \"honestly\", \"honestly\", \"ill\", \"inexpensive\", \"jam\", \"keep\", \"know\", \"know\", \"lancia\", \"last\", \"leave\", \"let\", \"life\", \"life\", \"long\", \"look\", \"lose\", \"low\", \"magnanimous\", \"maintain\", \"make\", \"make\", \"man\", \"man\", \"mate\", \"mechanic\", \"metre\", \"mile\", \"model\", \"moon\", \"morning\", \"motor\", \"mouth\", \"mouth\", \"move\", \"much\", \"much\", \"need\", \"night\", \"obviously\", \"oclock\", \"offroad\", \"open\", \"pan\", \"people\", \"possible\", \"power\", \"probably\", \"push\", \"put\", \"quite\", \"rally\", \"rally\", \"ready\", \"realistically\", \"really\", \"really\", \"replace\", \"ridiculous\", \"right\", \"rough\", \"run\", \"sad\", \"salt\", \"salt\", \"say\", \"say\", \"see\", \"see\", \"see\", \"see\", \"showroom\", \"simple\", \"simple\", \"slow\", \"soon\", \"special\", \"speed\", \"square\", \"stage\", \"stage\", \"stall\", \"starter\", \"stay\", \"stick\", \"stig\", \"still\", \"still\", \"stop\", \"stop\", \"struggle\", \"surface\", \"surprisingly\", \"surrey\", \"surrey\", \"take\", \"take\", \"take\", \"team\", \"tell\", \"think\", \"third\", \"tick\", \"time\", \"tip\", \"top\", \"true\", \"try\", \"turn\", \"turn\", \"twostroke\", \"tyre\", \"tyre\", \"unfortunately\", \"unmodified\", \"use\", \"use\", \"wait\", \"want\", \"watch\", \"water\", \"way\", \"way\", \"well\", \"wheel\", \"whole\", \"wide\", \"work\", \"world\", \"year\", \"zimbabwe\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 3, 5, 4, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1542418579891507525014665707\", ldavis_el1542418579891507525014665707_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1542418579891507525014665707\", ldavis_el1542418579891507525014665707_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1542418579891507525014665707\", ldavis_el1542418579891507525014665707_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1     -0.064187  0.180421       1        1  24.769145\n",
       "2     -0.081196 -0.194077       2        1  21.362234\n",
       "4     -0.178644  0.004536       3        1  18.774905\n",
       "3      0.149883 -0.123811       4        1  17.997135\n",
       "0      0.174146  0.132931       5        1  17.096580, topic_info=        Term       Freq      Total Category  logprob  loglift\n",
       "16       get  25.000000  25.000000  Default  30.0000  30.0000\n",
       "66     right  17.000000  17.000000  Default  29.0000  29.0000\n",
       "466  replace  13.000000  13.000000  Default  28.0000  28.0000\n",
       "59     think  14.000000  14.000000  Default  27.0000  27.0000\n",
       "107      top  13.000000  13.000000  Default  26.0000  26.0000\n",
       "..       ...        ...        ...      ...      ...      ...\n",
       "416    stage   0.862693   1.943257   Topic5  -5.5645   0.9542\n",
       "7       know   1.147563   4.785494   Topic5  -5.2792   0.3383\n",
       "83      make   1.394744  10.660455   Topic5  -5.0841  -0.2675\n",
       "162      bad   0.916030   2.610727   Topic5  -5.5045   0.7190\n",
       "19       see   0.832627   4.936446   Topic5  -5.6000  -0.0135\n",
       "\n",
       "[220 rows x 6 columns], token_table=      Topic      Freq        Term\n",
       "term                             \n",
       "284       4  0.984718  absolutely\n",
       "641       2  0.959078    actually\n",
       "285       4  0.552626     amazing\n",
       "214       4  0.893870        away\n",
       "383       1  0.912701        back\n",
       "...     ...       ...         ...\n",
       "173       5  0.764107        wide\n",
       "200       4  0.929384        work\n",
       "133       1  0.519853       world\n",
       "353       3  0.852807        year\n",
       "65        3  0.528651    zimbabwe\n",
       "\n",
       "[210 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 3, 5, 4, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the LDA model for 'X'\n",
    "vis = visualize_lda_model(results_dict, 'Clarkson')\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML for Presenters together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Variables from the results dictionary and declare new variables (copy n paste method)\n",
    "'''\n",
    "\n",
    "# Extract the variables for May\n",
    "lda_model_May = results_dict['May']['lda_model']\n",
    "corpus_May = results_dict['May']['corpus']\n",
    "dictionary_May = results_dict['May']['dictionary']\n",
    "\n",
    "lda_model_Hammond = results_dict['Hammond']['lda_model']\n",
    "corpus_Hammond = results_dict['Hammond']['corpus']\n",
    "dictionary_Hammond = results_dict['Hammond']['dictionary']\n",
    "\n",
    "# Similarly, you can extract and visualize for Clarkson and Hammond\n",
    "lda_model_Clarkson = results_dict['Clarkson']['lda_model']\n",
    "corpus_Clarkson = results_dict['Clarkson']['corpus']\n",
    "dictionary_Clarkson = results_dict['Clarkson']['dictionary']\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to generate and save PyLDAvis visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_vis(results_dict, name):\n",
    "    lda_model = results_dict[name]['lda_model']\n",
    "    corpus = results_dict[name]['corpus']\n",
    "    dictionary = results_dict[name]['dictionary']\n",
    "    vis = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "    pyLDAvis.save_html(vis, f'./outputs/vis_{name}.html')\n",
    "\n",
    "# Generate and save visualizations for each dataset\n",
    "for name in names:\n",
    "    generate_and_save_vis(results_dict, name)\n",
    "\n",
    "# Combine the HTML files into a single HTML file\n",
    "with open('combined_vis.html', 'w') as outfile:\n",
    "    for name in names:\n",
    "        with open(f'./outputs/vis_{name}.html') as infile:\n",
    "            outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "# Assuming lda_model_May, lda_model_Clarkson, and lda_model_Hammond are your LDA models\n",
    "# and corpus_May, corpus_Clarkson, corpus_Hammond are your corpora\n",
    "# and dictionary_May, dictionary_Clarkson, dictionary_Hammond are your dictionaries\n",
    "\n",
    "# Generate PyLDAvis visualizations\n",
    "vis_May = gensimvis.prepare(lda_model_May, corpus_May, dictionary_May)\n",
    "vis_Clarkson = gensimvis.prepare(lda_model_Clarkson, corpus_Clarkson, dictionary_Clarkson)\n",
    "vis_Hammond = gensimvis.prepare(lda_model_Hammond, corpus_Hammond, dictionary_Hammond)\n",
    "\n",
    "# Save each visualization as an HTML file\n",
    "pyLDAvis.save_html(vis_May, './outputs/vis_May.html')\n",
    "pyLDAvis.save_html(vis_Clarkson, './outputs/vis_Clarkson.html')\n",
    "pyLDAvis.save_html(vis_Hammond, './outputs/vis_Hammond.html')\n",
    "\n",
    "# Combine the HTML files into a single HTML file\n",
    "with open('./outputs/combined_vis.html', 'w') as outfile:\n",
    "    for fname in ['./outputs/vis_May.html', './outputs/vis_Clarkson.html', './outputs/vis_Hammond.html']:\n",
    "        with open(fname) as infile:\n",
    "            outfile.write(infile.read())\n",
    "\n",
    "# Now you can open 'combined_vis.html' to see all three visualizations together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Evaluation - Coherence \n",
    "\n",
    "Topic coherence measures the average similarity between top words having the highest weights in a topic i.e relative distance between the top words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score for May:  0.6808374806112967\n",
      "Coherence Score for Clarkson:  0.5909402916987949\n",
      "Coherence Score for Hammond:  0.6659895742797534\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for name in results_dict.keys():\n",
    "\tlda_model = results_dict[name]['lda_model']\n",
    "\ttexts = eval(f\"{name}_cleaned_texts\")\n",
    "\tdictionary = results_dict[name]['dictionary']\n",
    "\t\n",
    "\tcoherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "\tcoherence_lda = coherence_model_lda.get_coherence()\n",
    "\tprint(f'Coherence Score for {name}: ', coherence_lda)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Model Improvement - How many topics? \n",
    "\n",
    "## Define function to Iterate Coherence: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the function to iterate\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=1):\n",
    "\tcoherence_values = []\n",
    "\tmodel_list = []\n",
    "\t\n",
    "\tfor name in names:\n",
    "\t\tdictionary = results_dict[name]['dictionary']\n",
    "\t\tcorpus = results_dict[name]['corpus']\n",
    "\t\ttexts = eval(f\"{name}_cleaned_texts\")\n",
    "\t\t\n",
    "\t\tfor num_topics in range(start, limit, step):\n",
    "\t\t\tmodel = gensim.models.LdaModel(corpus=corpus, num_topics=num_topics, random_state=100, chunksize=200, passes=10, per_word_topics=True, id2word=dictionary)\n",
    "\t\t\tmodel_list.append(model)\n",
    "\t\t\tcoherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "\t\t\tcoherence_values.append(coherencemodel.get_coherence())\n",
    "\t\n",
    "\treturn model_list, coherence_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for May:\n",
      "Num Topics = 2, Coherence Value = 0.7166129819455946\n",
      "Num Topics = 3, Coherence Value = 0.7157485205762296\n",
      "Num Topics = 4, Coherence Value = 0.6874794865478038\n",
      "Num Topics = 5, Coherence Value = 0.6808374806112967\n",
      "Num Topics = 6, Coherence Value = 0.645575251871593\n",
      "Num Topics = 7, Coherence Value = 0.584938584949688\n",
      "Num Topics = 8, Coherence Value = 0.5339173988933685\n",
      "Num Topics = 9, Coherence Value = 0.5369284102274318\n",
      "Results for Clarkson:\n",
      "Num Topics = 2, Coherence Value = 0.7166129819455946\n",
      "Num Topics = 3, Coherence Value = 0.7157485205762296\n",
      "Num Topics = 4, Coherence Value = 0.6874794865478038\n",
      "Num Topics = 5, Coherence Value = 0.6808374806112967\n",
      "Num Topics = 6, Coherence Value = 0.645575251871593\n",
      "Num Topics = 7, Coherence Value = 0.584938584949688\n",
      "Num Topics = 8, Coherence Value = 0.5339173988933685\n",
      "Num Topics = 9, Coherence Value = 0.5369284102274318\n",
      "Results for Hammond:\n",
      "Num Topics = 2, Coherence Value = 0.7166129819455946\n",
      "Num Topics = 3, Coherence Value = 0.7157485205762296\n",
      "Num Topics = 4, Coherence Value = 0.6874794865478038\n",
      "Num Topics = 5, Coherence Value = 0.6808374806112967\n",
      "Num Topics = 6, Coherence Value = 0.645575251871593\n",
      "Num Topics = 7, Coherence Value = 0.584938584949688\n",
      "Num Topics = 8, Coherence Value = 0.5339173988933685\n",
      "Num Topics = 9, Coherence Value = 0.5369284102274318\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Call the function and print the results for each name in results_dict\n",
    "limit = 10\n",
    "start = 2\n",
    "step = 1\n",
    "\n",
    "for name in names:\n",
    "\tprint(f\"Results for {name}:\")\n",
    "\tmodel_list, coherence_values = compute_coherence_values(results_dict[name]['dictionary'], results_dict[name]['corpus'], eval(f\"{name}_cleaned_texts\"), limit, start, step)\n",
    "\tfor m, cv in zip(range(start, limit, step), coherence_values):\n",
    "\t\tprint(f\"Num Topics = {m}, Coherence Value = {cv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisperx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
