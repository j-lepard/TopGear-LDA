{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Automatic Speech Recognition, Diarize and Label\n",
    "\n",
    "Environment = \"whisperx\"\n",
    "\n",
    "* Performance Benchmarks on local\n",
    "* GPU Benchmark: 0.09961056709289551 seconds\n",
    "* Memory Bandwidth Benchmark: 0.2920224666595459 seconds\n",
    "* CPU Benchmark: 13.046526432037354 seconds\n",
    "* Disk Write Benchmark: 2.3364615440368652 seconds\n",
    "* Disk Read Benchmark: 0.05882525444030762 seconds \\n\n",
    "  \n",
    "** all benchmarks are >> faster than Collab with the exception of Disk write.\n",
    "\n",
    "## Setup ⚙️\n",
    "Tested for PyTorch 2.0, Python 3.10 (use other versions at your own risk!)\n",
    "GPU execution requires the NVIDIA libraries cuBLAS 11.x and cuDNN 8.x to be installed on the system. Please refer to the CTranslate2 documentation.\n",
    "\n",
    "1.  Create Python3.10 environment\n",
    "\n",
    "`conda create --name whisperx python=3.10`\n",
    "\n",
    "`conda activate whisperx`\n",
    "\n",
    "2. Install PyTorch, e.g. for Linux and Windows CUDA11.8:\n",
    "   \n",
    "conda install pytorch==2.0.0 torchaudio==2.0.0 pytorch-cuda=11.8 -c pytorch -c nvidia\n",
    "\n",
    "See other methods here.\n",
    "\n",
    "1. Install this repo\n",
    "\n",
    "`pip install git+https://github.com/m-bain/whisperx.git`\n",
    "\n",
    "If already installed, update package to most recent commit\n",
    "\n",
    "`pip install git+https://github.com/m-bain/whisperx.git --upgrade`\n",
    "\n",
    "## Post Setup - REQUIRED for DIARIZATION **Actually dont do this!!\n",
    "https://github.com/m-bain/whisperX/issues/499\n",
    "\n",
    "`pip install pyannote.audio==3.0.1`\n",
    "\n",
    "`pip uninstall onnxruntime`\n",
    "\n",
    "`pip install --force-reinstall onnxruntime-gpu`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess initial audio file\n",
    "convert to Wav using ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "\n",
    "## 1 - Convert Mp3 to WAV.\n",
    "\n",
    "def convert_m4a_to_mp3(input_file, output_file):\n",
    "    try:\n",
    "        ffmpeg.input(input_file).output(output_file).run(overwrite_output=True)\n",
    "        print(f\"Successfully converted {input_file} to {output_file}\")\n",
    "    except ffmpeg.Error as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "# Input/ output files and usage\n",
    "input_mp3 = './audio/Botswana_2007_Audio.mp3'  # Change this to your mp3 file path\n",
    "output_wav = './data/Botswana_2007_Audio.wav'  # Change this to your desired output wav file path\n",
    "\n",
    "convert_m4a_to_mp3(input_mp3, output_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jamie\\miniconda3\\envs\\whisperx\\lib\\inspect.py:869: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n",
      "c:\\Users\\jamie\\miniconda3\\envs\\whisperx\\lib\\site-packages\\pyannote\\audio\\pipelines\\speaker_verification.py:45: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  from speechbrain.pretrained import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully accessed the audio file: ./data/Botswana_2007_Audio.wav\n"
     ]
    }
   ],
   "source": [
    "import whisperx\n",
    "import gc\n",
    "import os\n",
    "import torch\n",
    "\n",
    "device = \"cuda\"\n",
    "## Full file should be the input (2007 or 2024 file..)\n",
    "audio_file = \"./data/Botswana_2007_Audio.wav\"\n",
    "\n",
    "## DEBUGGING, use a small file\n",
    "# audio_file = \"./data/Intro.wav\"\n",
    "\n",
    "batch_size = 16 # reduce if low on GPU mem\n",
    "compute_type = \"float16\" # change to \"int8\" if low on GPU mem (may reduce accuracy)\n",
    "without_timestamps= 'True'\n",
    "\n",
    "## Some error handling to ensure that successfully loaded the mp3 file!\n",
    "try:\n",
    "    # Check if the file exists\n",
    "    if not os.path.isfile(audio_file):\n",
    "        raise FileNotFoundError(f\"The file '{audio_file}' does not exist.\")\n",
    "    # Optionally, you can add more checks (like file format) here\n",
    "\n",
    "    print(f\"Successfully accessed the audio file: {audio_file}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jamie\\miniconda3\\envs\\whisperx\\lib\\inspect.py:869: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n",
      "c:\\Users\\jamie\\miniconda3\\envs\\whisperx\\lib\\site-packages\\pyannote\\audio\\pipelines\\speaker_verification.py:45: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  from speechbrain.pretrained import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully accessed the audio file: ./data/Botswana_2007_Audio.wav\n"
     ]
    }
   ],
   "source": [
    "import whisperx\n",
    "import gc\n",
    "import os\n",
    "import torch\n",
    "\n",
    "device = \"cuda\"\n",
    "## Full file should be the input (2007 or 2024 file..)\n",
    "audio_file = \"./data/Botswana_2007_Audio.wav\"\n",
    "\n",
    "## DEBUGGING, use a small file\n",
    "# audio_file = \"./data/Intro.wav\"\n",
    "\n",
    "batch_size = 16 # reduce if low on GPU mem\n",
    "compute_type = \"float16\" # change to \"int8\" if low on GPU mem (may reduce accuracy)\n",
    "without_timestamps= 'True'\n",
    "\n",
    "## Some error handling to ensure that successfully loaded the mp3 file!\n",
    "try:\n",
    "    # Check if the file exists\n",
    "    if not os.path.isfile(audio_file):\n",
    "        raise FileNotFoundError(f\"The file '{audio_file}' does not exist.\")\n",
    "    # Optionally, you can add more checks (like file format) here\n",
    "\n",
    "    print(f\"Successfully accessed the audio file: {audio_file}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Batches\n",
    "\n",
    "### Split the Audio file into smaller pieces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3 - Split up large files in <10min\n",
    "\n",
    "\n",
    "import sqlite3\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import math\n",
    "\n",
    "\n",
    "# TODO: change max duration to 300 seconds\n",
    "# TODO: update the target database folder\n",
    "# TODO: check input filenames\n",
    "# TODO: Update the output folder\n",
    "\n",
    "# Function to split audio and save to database\n",
    "def split_audio(audio_file, max_duration=300):  # 60second (1min) for testing; 300sec for production\n",
    "    conn = sqlite3.connect('./data/Audio_clips.db')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''CREATE TABLE IF NOT EXISTS clips\n",
    "                     (id INTEGER PRIMARY KEY AUTOINCREMENT, start_time REAL, end_time REAL, filename TEXT)''')\n",
    "\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading audio file: {e}\")\n",
    "        return []\n",
    "\n",
    "    total_duration = librosa.get_duration(y=y, sr=sr)\n",
    "    num_splits = math.ceil(total_duration / max_duration)\n",
    "    results = []\n",
    "\n",
    "    for i in range(num_splits):\n",
    "        start_time = i * max_duration\n",
    "        end_time = min((i + 1) * max_duration, total_duration)\n",
    "\n",
    "        start_sample = int(start_time * sr)\n",
    "        end_sample = int(end_time * sr)\n",
    "\n",
    "        clip = y[start_sample:end_sample]\n",
    "        filename = f\"./data/Botswana2007_clip_{i}.wav\"\n",
    "\n",
    "        try:\n",
    "            sf.write(filename, clip, sr)\n",
    "            cursor.execute(\"INSERT INTO clips (start_time, end_time, filename) VALUES (?, ?, ?)\",\n",
    "                           (start_time, end_time, filename))\n",
    "            conn.commit()\n",
    "            results.append({\"start_time\": start_time, \"end_time\": end_time, \"filename\": filename})\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing clip {i}: {e}\")\n",
    "\n",
    "    conn.close()\n",
    "    return results\n",
    "# results is a DIctionary\n",
    "results = split_audio(audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BATCH PROCESS: Transcript - Align - Diarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1 - use python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSCRIBING & ALIGNING using device: cuda\n",
      "Compute type is float16\n",
      "Processing file: ./data/Testing\\Intro_clip_0.wav\n",
      "No language specified, language will be first be detected for each audio file (increases inference time).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\jamie\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "STARTING Transcription on ./data/Testing\\Intro_clip_0.wav\n",
      "Detected language: en (0.99) in first 30s of audio...\n",
      "[{'text': ' And welcome! Thank you very much. Now, as you know, the producers on this show like to give us challenges. Specifically, where they give us a very small amount of money and tell us to buy a used car. Then they set unbelievably hard tasks to do to see which one of us got the best deal. Yeah. This week, for a Top Gear special, they came up with a real humdinger. They gave each of us 1,500 quid and told us to go to Africa and buy a car.', 'start': 0.009, 'end': 28.302}, {'text': \" Yeah, there were just two conditions. It mustn't be four-wheel drive and it mustn't be built in any way to go off-road. The meeting point was the border post between Zimbabwe and Botswana. And, for once, I was the first to arrive.\", 'start': 28.302, 'end': 49.582}, {'text': \" Now, as you'd expect, I've done this properly. What I've got is a 1985 Mercedes-Benz 230e, a car that...\", 'start': 52.568, 'end': 59.991}]\n",
      "STARTING ALIGNMENT on ./data/Testing\\Intro_clip_0.wav\n",
      "STARTING DIARIZE on ./data/Testing\\Intro_clip_0.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import gc\n",
    "import torch\n",
    "import whisperx\n",
    "from HF_token import TOKEN_ID\n",
    "\n",
    "# Directory containing .wav files\n",
    "wav_directory = './data/Testing'\n",
    "\n",
    "# Get a list of all .wav files in the directory\n",
    "wav_files = glob.glob(os.path.join(wav_directory, '*.wav'))\n",
    "\n",
    "# Initialize results_full list\n",
    "aligned_results_full = []\n",
    "\n",
    "# Set device and compute type\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "compute_type = \"float16\" if device == \"cuda\" else \"float32\"\n",
    "\n",
    "print(f\"TRANSCRIBING & ALIGNING using device: {device}\")\n",
    "print(f\"Compute type is {compute_type}\")\n",
    "\n",
    "# Ensure the model directory exists\n",
    "model_dir = \"./model/\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 16  # Adjust as needed\n",
    "\n",
    "# # Load the model and save it to the local path\n",
    "# try:\n",
    "#     model = whisperx.load_model(\"large-v2\", device=device, compute_type=compute_type, download_root=model_dir)\n",
    "# except Exception as e:\n",
    "#     print(f\"Error loading model: {e}\")\n",
    "#     raise\n",
    "\n",
    "# Iterate through each .wav file and process it\n",
    "for wav_file in wav_files:\n",
    "    print(f\"Processing file: {wav_file}\")\n",
    "    try:\n",
    "        # Load the audio file\n",
    "        audio = whisperx.load_audio(wav_file)\n",
    "        \n",
    "        # Ensure the output directory exists\n",
    "        output_dir = \"./outputs/Testing\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        #####################     TRANSCRIPTION  #################\n",
    "        # Load the model and save it to the local path\n",
    "        try:\n",
    "            model = whisperx.load_model(\"large-v2\", device=device, compute_type=compute_type, download_root=model_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            raise\n",
    "\n",
    "        print(f\"STARTING Transcription on {wav_file}\")\n",
    "\n",
    "        # Transcribe the audio file\n",
    "        transcribe_result = model.transcribe(audio, batch_size=batch_size)\n",
    "        print(transcribe_result[\"segments\"])  # before alignment\n",
    "        \n",
    "        # Save the transcription result to a JSON file\n",
    "        transcript_filename = os.path.basename(wav_file).replace('.wav', '')\n",
    "        with open(f'./outputs/Testing/{transcript_filename}_transcript.json', 'w') as json_file:\n",
    "            json.dump(transcribe_result, json_file, indent=4)\n",
    "        \n",
    "        \n",
    "\n",
    "        #####################     ALIGNMENT #################\n",
    "        print(f\"STARTING ALIGNMENT on {wav_file}\")\n",
    "        \n",
    "        # Load the alignment model with the specified device\n",
    "        model_a, metadata = whisperx.load_align_model(language_code=\"en\", device=device)\n",
    "        \n",
    "        # Perform alignment using the specified device\n",
    "        aligned_result = whisperx.align(transcribe_result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=False)\n",
    "        \n",
    "        # Save the Alignment result to a JSON file\n",
    "        alignment_filename = os.path.basename(wav_file).replace('.wav', '')\n",
    "        with open(f'./outputs/Testing/{alignment_filename}_aligned.json', 'w') as json_file:\n",
    "            json.dump(aligned_result, json_file, indent=4)\n",
    "        \n",
    "        # Append the aligned result to results_full\n",
    "        aligned_results_full.append(aligned_result)\n",
    "        \n",
    "        #####################     DIARIZE #################\n",
    "        print(f\"STARTING DIARIZE on {wav_file}\")\n",
    "\n",
    "        # Load the DIARIZE Model\n",
    "        diarize_model = whisperx.DiarizationPipeline(use_auth_token=TOKEN_ID, device=device)\n",
    "\n",
    "        # Load the audio data\n",
    "        audio_data = {\n",
    "            'waveform': torch.from_numpy(audio[None, :]),\n",
    "            'sample_rate': whisperx.audio.SAMPLE_RATE\n",
    "                    }\n",
    "        # Run the diarization model\n",
    "        diarize_segments = diarize_model(audio)\n",
    "\n",
    "        # add min/max number of speakers if known\n",
    "        diarize_model(audio, min_speakers=1, max_speakers=3)\n",
    "\n",
    "        # Assign speaker labels to words\n",
    "        diarize_result = whisperx.assign_word_speakers(diarize_segments, aligned_result)\n",
    "\n",
    "        ## SAVE the TRANSCRIPT\n",
    "        diarized_filename = os.path.basename(wav_file).replace('.wav', '')\n",
    "        with open(f'./outputs/Testing/{diarized_filename}_diarized.json', 'w') as json_file:\n",
    "            json.dump(diarize_result, json_file, indent=4)\n",
    "     \n",
    "       # Clean up memory after each file\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {wav_file}: {e}\")\n",
    "\n",
    "# Optionally, save the full results to a single JSON file\n",
    "with open('./outputs/Testing/full_alignment.json', 'w') as json_file:\n",
    "    json.dump(aligned_results_full, json_file, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2 - use the Terminal and CLI \n",
    "This seemed to work on a single file VERY fast! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from HF_token import TOKEN_ID\n",
    "# Set the path to your directory\n",
    "directory = \"./data/Testing/\"\n",
    "\n",
    "# Iterate through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".wav\"):  # Check for .wav files\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Construct and run the whisperx command for each file\n",
    "        command = f\"whisperx {filepath} --model large-v2 --diarize --highlight_words True --hf_token {TOKEN_ID}\"\n",
    "        os.system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Approach 2B - add some subprocess to monitor progress\n",
    "\n",
    " This method is *best* as a) actually worked and b) provided insight into what is going on! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Botswana2007_clip_0.wav\n",
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      ">>Performing transcription...\n",
      "Detected language: en (0.99) in first 30s of audio...\n",
      ">>Performing alignment...\n",
      ">>Performing diarization...\n",
      "Completed file: Botswana2007_clip_0.wav\n",
      "\n",
      "Processing file: Botswana2007_clip_1.wav\n",
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      ">>Performing transcription...\n",
      "Detected language: en (1.00) in first 30s of audio...\n",
      ">>Performing alignment...\n",
      ">>Performing diarization...\n",
      "Completed file: Botswana2007_clip_1.wav\n",
      "\n",
      "Processing file: Botswana2007_clip_10.wav\n",
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      ">>Performing transcription...\n",
      "Detected language: en (1.00) in first 30s of audio...\n",
      ">>Performing alignment...\n",
      ">>Performing diarization...\n",
      "Completed file: Botswana2007_clip_10.wav\n",
      "\n",
      "Processing file: Botswana2007_clip_11.wav\n",
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      ">>Performing transcription...\n",
      "Detected language: en (1.00) in first 30s of audio...\n",
      ">>Performing alignment...\n",
      ">>Performing diarization...\n",
      "Completed file: Botswana2007_clip_11.wav\n",
      "\n",
      "Processing file: Botswana2007_clip_2.wav\n",
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      ">>Performing transcription...\n",
      "Detected language: en (1.00) in first 30s of audio...\n",
      ">>Performing alignment...\n",
      ">>Performing diarization...\n",
      "Completed file: Botswana2007_clip_2.wav\n",
      "\n",
      "Processing file: Botswana2007_clip_3.wav\n",
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      ">>Performing transcription...\n",
      "Detected language: en (1.00) in first 30s of audio...\n",
      ">>Performing alignment...\n",
      ">>Performing diarization...\n",
      "Completed file: Botswana2007_clip_3.wav\n",
      "\n",
      "Processing file: Botswana2007_clip_4.wav\n",
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      ">>Performing transcription...\n",
      "Detected language: en (1.00) in first 30s of audio...\n",
      ">>Performing alignment...\n",
      ">>Performing diarization...\n",
      "Completed file: Botswana2007_clip_4.wav\n",
      "\n",
      "Processing file: Botswana2007_clip_5.wav\n",
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      ">>Performing transcription...\n",
      "Detected language: en (1.00) in first 30s of audio...\n",
      ">>Performing alignment...\n",
      ">>Performing diarization...\n",
      "Completed file: Botswana2007_clip_5.wav\n",
      "\n",
      "Processing file: Botswana2007_clip_6.wav\n",
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      ">>Performing transcription...\n",
      "Detected language: en (1.00) in first 30s of audio...\n",
      ">>Performing alignment...\n",
      ">>Performing diarization...\n",
      "Completed file: Botswana2007_clip_6.wav\n",
      "\n",
      "Processing file: Botswana2007_clip_7.wav\n",
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      ">>Performing transcription...\n",
      "Detected language: en (1.00) in first 30s of audio...\n",
      ">>Performing alignment...\n",
      ">>Performing diarization...\n",
      "Completed file: Botswana2007_clip_7.wav\n",
      "\n",
      "Processing file: Botswana2007_clip_8.wav\n",
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      ">>Performing transcription...\n",
      "Detected language: en (1.00) in first 30s of audio...\n",
      ">>Performing alignment...\n",
      ">>Performing diarization...\n",
      "Completed file: Botswana2007_clip_8.wav\n",
      "\n",
      "Processing file: Botswana2007_clip_9.wav\n",
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      ">>Performing transcription...\n",
      "Detected language: en (1.00) in first 30s of audio...\n",
      ">>Performing alignment...\n",
      ">>Performing diarization...\n",
      "Completed file: Botswana2007_clip_9.wav\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from HF_token import TOKEN_ID\n",
    "\n",
    "# Set the path to your directory\n",
    "directory = \"data/\"\n",
    "\n",
    "# Iterate through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".wav\"):  # Check for .wav files\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Print the filename to show progress\n",
    "        print(f\"Processing file: {filename}\")\n",
    "        \n",
    "        # Construct the whisperx command for each file\n",
    "        command = f\"whisperx {filepath} --model large-v2 --diarize --highlight_words True --hf_token {TOKEN_ID} --output_dir ./outputs\"\n",
    "        \n",
    "        # Run the command and capture real-time output\n",
    "        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        \n",
    "        # Display real-time output from the command\n",
    "        for line in process.stdout:\n",
    "            print(line.decode().strip())\n",
    "        \n",
    "        process.wait()  # Wait for process to finish\n",
    "        \n",
    "        # Confirm completion for each file\n",
    "        print(f\"Completed file: {filename}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consolidate the Diarized JSON files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.467</td>\n",
       "      <td>23.068</td>\n",
       "      <td>Hello, hello, and welcome.</td>\n",
       "      <td>[{'word': 'Hello,', 'start': 21.467, 'end': 21...</td>\n",
       "      <td>SPEAKER_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.108</td>\n",
       "      <td>24.029</td>\n",
       "      <td>Thank you very much.</td>\n",
       "      <td>[{'word': 'Thank', 'start': 23.108, 'end': 23....</td>\n",
       "      <td>SPEAKER_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.049</td>\n",
       "      <td>34.256</td>\n",
       "      <td>Now, as you know, the producers on this show l...</td>\n",
       "      <td>[{'word': 'Now,', 'start': 24.049, 'end': 24.1...</td>\n",
       "      <td>SPEAKER_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.597</td>\n",
       "      <td>39.640</td>\n",
       "      <td>Then they set unbelievably hard tasks to do to...</td>\n",
       "      <td>[{'word': 'Then', 'start': 34.597, 'end': 34.7...</td>\n",
       "      <td>SPEAKER_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.900</td>\n",
       "      <td>40.080</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>[{'word': 'Yeah.', 'start': 39.9, 'end': 40.08...</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>73.436</td>\n",
       "      <td>76.317</td>\n",
       "      <td>They work very well on that wheel, but only on...</td>\n",
       "      <td>[{'word': 'They', 'start': 73.436, 'end': 73.5...</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>77.117</td>\n",
       "      <td>78.638</td>\n",
       "      <td>And that instrument's a bit wobbly.</td>\n",
       "      <td>[{'word': 'And', 'start': 77.117, 'end': 77.21...</td>\n",
       "      <td>SPEAKER_03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>78.658</td>\n",
       "      <td>82.560</td>\n",
       "      <td>Apart from that, everything that's actually im...</td>\n",
       "      <td>[{'word': 'Apart', 'start': 78.658, 'end': 78....</td>\n",
       "      <td>SPEAKER_03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>83.560</td>\n",
       "      <td>86.882</td>\n",
       "      <td>Apart from the handbrake, which I can pull lik...</td>\n",
       "      <td>[{'word': 'Apart', 'start': 83.56, 'end': 83.8...</td>\n",
       "      <td>SPEAKER_03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>88.453</td>\n",
       "      <td>93.758</td>\n",
       "      <td>Nevertheless, because we were on tarmac roads...</td>\n",
       "      <td>[{'word': 'Nevertheless,', 'start': 88.453, 'e...</td>\n",
       "      <td>SPEAKER_02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     start     end                                               text  \\\n",
       "0   21.467  23.068                         Hello, hello, and welcome.   \n",
       "1   23.108  24.029                               Thank you very much.   \n",
       "2   24.049  34.256  Now, as you know, the producers on this show l...   \n",
       "3   34.597  39.640  Then they set unbelievably hard tasks to do to...   \n",
       "4   39.900  40.080                                              Yeah.   \n",
       "..     ...     ...                                                ...   \n",
       "95  73.436  76.317  They work very well on that wheel, but only on...   \n",
       "96  77.117  78.638                And that instrument's a bit wobbly.   \n",
       "97  78.658  82.560  Apart from that, everything that's actually im...   \n",
       "98  83.560  86.882  Apart from the handbrake, which I can pull lik...   \n",
       "99  88.453  93.758   Nevertheless, because we were on tarmac roads...   \n",
       "\n",
       "                                                words     speaker  \n",
       "0   [{'word': 'Hello,', 'start': 21.467, 'end': 21...  SPEAKER_02  \n",
       "1   [{'word': 'Thank', 'start': 23.108, 'end': 23....  SPEAKER_02  \n",
       "2   [{'word': 'Now,', 'start': 24.049, 'end': 24.1...  SPEAKER_02  \n",
       "3   [{'word': 'Then', 'start': 34.597, 'end': 34.7...  SPEAKER_02  \n",
       "4   [{'word': 'Yeah.', 'start': 39.9, 'end': 40.08...  SPEAKER_00  \n",
       "..                                                ...         ...  \n",
       "95  [{'word': 'They', 'start': 73.436, 'end': 73.5...  SPEAKER_00  \n",
       "96  [{'word': 'And', 'start': 77.117, 'end': 77.21...  SPEAKER_03  \n",
       "97  [{'word': 'Apart', 'start': 78.658, 'end': 78....  SPEAKER_03  \n",
       "98  [{'word': 'Apart', 'start': 83.56, 'end': 83.8...  SPEAKER_03  \n",
       "99  [{'word': 'Nevertheless,', 'start': 88.453, 'e...  SPEAKER_02  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "\n",
    "# Directory containing the JSON files\n",
    "json_directory = 'outputs/'\n",
    "\n",
    "# Get a list of all JSON files in the directory\n",
    "json_files = glob.glob(os.path.join(json_directory, '*.json'))\n",
    "\n",
    "# Initialize a list to hold all DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Iterate through each JSON file and merge segments\n",
    "for json_file in json_files:\n",
    "\twith open(json_file, 'r') as file:\n",
    "\t\tdata = json.load(file)\n",
    "\t\t# Convert the \"segments\" part of the JSON data to a DataFrame\n",
    "\t\tdf = pd.DataFrame(data[\"segments\"])\n",
    "\t\tdf_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "diarized_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Export\n",
    "diarized_df.to_csv('./data/diarzed_output_no_names.csv')\n",
    "\n",
    "# Display the consolidated DataFrame\n",
    "diarized_df.head(100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the Speaker names to the labels\n",
    "\n",
    "diarized_df['speaker'] = diarized_df['speaker'].replace('SPEAKER_01', 'May')\n",
    "diarized_df['speaker'] = diarized_df['speaker'].replace('SPEAKER_02', 'Clarkson')\n",
    "diarized_df['speaker'] = diarized_df['speaker'].replace('SPEAKER_00', 'Hammond')\n",
    "\n",
    "diarized_df.head(100)\n",
    "\n",
    "# Export\n",
    "diarized_df.to_csv('./data/diarzed_output_named.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: LDA (Latent Dirichlet Allocation) Preparation\n",
    "### Import the previously created json/csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Import\n",
    "diarized_df = pd.read_csv('./data/diarzed_output_named.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all the libraries required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#1introduction\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "\n",
    "#Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "#spacy\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#vis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "### Cant remember why needed this ... \n",
    "import locale\n",
    "def getpreferredencoding(do_setlocale=True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data frame into 3 (one per presenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker 01 [James] DataFrame:\n",
      "\n",
      "Speaker 02[Jeremy] DataFrame:\n",
      "\n",
      "Speaker 03 [Richard] DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.900</td>\n",
       "      <td>40.080</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>[{'word': 'Yeah.', 'start': 39.9, 'end': 40.08...</td>\n",
       "      <td>Hammond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40.541</td>\n",
       "      <td>44.043</td>\n",
       "      <td>This week, for a Top Gear special, they came u...</td>\n",
       "      <td>[{'word': 'This', 'start': 40.541, 'end': 40.7...</td>\n",
       "      <td>Hammond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44.423</td>\n",
       "      <td>50.408</td>\n",
       "      <td>They gave each of us 1,500 quid and told us to...</td>\n",
       "      <td>[{'word': 'They', 'start': 44.423, 'end': 44.5...</td>\n",
       "      <td>Hammond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>149.354</td>\n",
       "      <td>155.119</td>\n",
       "      <td>What the hell have you done, man?</td>\n",
       "      <td>[{'word': 'What', 'start': 149.354, 'end': 149...</td>\n",
       "      <td>Hammond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>155.419</td>\n",
       "      <td>156.960</td>\n",
       "      <td>It's an Opel Cadet from 1963.</td>\n",
       "      <td>[{'word': 'It's', 'start': 155.419, 'end': 155...</td>\n",
       "      <td>Hammond</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      start      end                                               text  \\\n",
       "4    39.900   40.080                                              Yeah.   \n",
       "5    40.541   44.043  This week, for a Top Gear special, they came u...   \n",
       "6    44.423   50.408  They gave each of us 1,500 quid and told us to...   \n",
       "41  149.354  155.119                  What the hell have you done, man?   \n",
       "42  155.419  156.960                      It's an Opel Cadet from 1963.   \n",
       "\n",
       "                                                words  speaker  \n",
       "4   [{'word': 'Yeah.', 'start': 39.9, 'end': 40.08...  Hammond  \n",
       "5   [{'word': 'This', 'start': 40.541, 'end': 40.7...  Hammond  \n",
       "6   [{'word': 'They', 'start': 44.423, 'end': 44.5...  Hammond  \n",
       "41  [{'word': 'What', 'start': 149.354, 'end': 149...  Hammond  \n",
       "42  [{'word': 'It's', 'start': 155.419, 'end': 155...  Hammond  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt: use align_df to create 3 new dataframes using the Speaker field\n",
    "\n",
    "# Create a new DataFrame for each speaker\n",
    "May_df = diarized_df[diarized_df['speaker'] == 'May']\n",
    "Clarkson_df = diarized_df[diarized_df['speaker'] == 'Clarkson']\n",
    "Hammond_df = diarized_df[diarized_df['speaker'] == 'Hammond']\n",
    "\n",
    "# Display the first few rows of each DataFrame (optional)\n",
    "May_df.head()\n",
    "\n",
    "# Clarkson_df.head()\n",
    "\n",
    "# Hammond_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PREPROCESS\n",
    "Remove emails, newline char, stop words, and tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yeah, there were just two conditions.', 'It mustnt be four-wheel drive, and it mustnt be built in any way to go off-road.', 'The meeting point was the border post between Zimbabwe and Botswana.', 'And, for once, I was the first to arrive.', 'Now, as youd expect, Ive done this properly.', 'What Ive got is a 1985 Mercedes-Benz 230e, a car that Africa absolutely adores, because its comfortable, its rugged, its dependable, and frankly, if the other two have brought anything other than one of these along, theyre idiots.', 'The first idiot arrived.', 'Can you open the door?', 'The handles broken.', 'Yeah, thats normal, isnt it?', 'That fizzing?', 'Thats... Yeah.', 'Whats the piece of cardboard for?', 'Is that for mopping up moisture?', 'So, now what?', 'Do you want a lift?', 'We left the Lancia to cool down, because Hammond was arriving.', 'Youve both been idiots.', 'No.', 'Brilliantly interesting, brilliantly stylish, but stupid.', 'Im confident.', 'Right, Im going to overtake the truck.', 'Here I go.', 'Hes pulled out of its slipstream.', 'Well, its really coming up.', 'Still truck.', 'Still truck.', 'Hammond, hows it going?', 'We did as well, but it doesnt matter because we used some rifles.', 'We shot the cars and the waters all drained out.', 'Its brilliant.', 'You are going to try and mend this?', 'So we did.', 'Oh, I like this one.', 'Its sad, so sad.', 'Its a sad, sad situation.', 'Unfortunately, you can only give a man so much sympathy.', 'So James and I went ahead to make camp.', 'Hammond knew that in the morning, if his beloved Oliver wasnt fixed, hed have to leave him behind.', 'So he got our bush mechanic to bring the generator down... ..and worked on through the night.', 'Morning came and still no Hammond.', 'What happened today?', 'I mean, Im feeling quite like an explorer.', 'No way.', 'Is that technically possible?', 'Probably not.', 'For 47 years, Ive never been speechless.', 'With all the cars defying all the odds, we began our final push to the border.', 'The Lancia could beat that.', 'Every time I brake, it spears off to the right and Im unable to steer left to correct that.', 'This has now gone from being a nuisance to being downright dangerous.', 'It had that feel of a car that was dying.', 'Richard actually sympathised, because hed been there.', 'As for James... A vehicle.', 'Im not going to give in.', 'Ill push it.', 'There you go.', 'This is an object lesson for the owners of old cars everywhere.', 'You can drive them round the world.', 'Come on.', '1,596 kilometres.', 'Thats near as damn it a thousand miles.', 'Ive still got half a car left and very bad hair.', 'I dont believe that.', 'Oliver is just skipping.', 'Boom!', 'This car was born to do this.', 'Meanwhile, in my unmodified cadet... Im going to adjust my quarter light a bit.', 'Just an inch.', 'Thats better.', 'Its my car on the crab.', 'No, its tracking Troentruve.', 'Hes worried about tracking, and look at it.', 'We knew that Jeremy would eventually catch us up, but what would he be driving?', 'I can see something in the mirrors.', 'Please, please let it be a Beetle.', 'With their convoy back on the road,', 'Annoyingly, Clarkson got the lancet going again.', 'And then we came across some big birds.', 'Wow!', 'Two cows, three cows.', 'Personally, Im absolutely delighted because I think the Macaddy Caddy is one of the most unpleasant places Ive ever been.', 'Its just a big bowl of dust.', 'Hello, mate.', 'Ive got goosebumps.', 'I know a Philip Larkin poem about the moon.', 'Would you like to hear it?', 'No.', 'Hes protecting the important bits.', 'Keen to get going, the three of us fired up our engines.', 'Well, when I say three.', 'Annoyingly, a couple of the locals did know what to do.', 'And we drove to African Stigs rally stage, which was in a dried-up riverbed a few miles away.', 'With packed spectator stands, Oliver went first.', 'Three, two...', 'Three miles an hour.', 'It is eminent.', 'Come on, joggle it, Stigs cousin.', 'Thats not dust, its on fire!', 'Can I turn it off?', 'Look at it all!', 'Once again, the broken lance here was fixed.', 'And then Jeremy arrived with some woe for all of us.', 'What?', 'Forget some of it.', 'Thats it.', 'Those are the fuel cans.', 'The town of Maun was about 60 miles away, and with little fuel, wed have to go there as the crow flies.', 'Now we really would see how theyd cope off-road.', 'Weve got to try and keep the distance down to save what fuel weve got.', 'Once again, the 44-year-old Opel absolutely shone.', 'With our precious fuel burning away, we carved out the straightest path possible.', 'Horn doesnt work.', 'Clearly, Id have to get myself out.', 'Im going to make a rudimentary temporary road for my back wheel.', 'Thank God.', 'We were now just over halfway, and amazingly, our cars were still running.', 'All of them.', 'The next day, in the centre of Maun, we got our next challenge.', 'The Glittering Golden Envelope.', 'You will drive your cars to Namibia through the Okavango Delta.', 'Thats the really big wildlife place.', 'In the Okavango, you will encounter many deadly animals, including lions, leopards, cheetahs, hyenas, wild dogs, hippos, black rhino and crocodile.', 'Bird snakes, shield-nosed snakes, puff adders, boomslang, cape cobras, banded cobras, black mambas, black widows and thick-tailed scorpions.', 'In order to protect ourselves from the lions and the honey badgers, Jeremy and I would have to rebuild our cars.', 'But because wed left all the bits on the other side of the salt pans, we had to use whatever we could find.', 'Did a lion eat this?', 'Who do I see about the corrugated metal?', 'Could you put a new door on a car?', 'Come and have a look.', 'Ill show you what I mean.', 'Its not sophisticated metalwork, this, but...', 'Can anybody else smell burning or is it my car?', 'Is it like a barbecue smell?', 'As we neared the Okavango, the roads became rougher and rougher.', 'This is where the Big Ben comes into its own, really, because its got good ground clearance, nothing... Bloody hell.', 'So, just to summarise, viewers... As we went through the gates and into the game reserve, the road changed again, for the worse.', 'Very soft sand.', 'To stop our cars bogging down, we had to drive as fast as possible.', 'We had ourselves another rally stage.', 'Amazingly, even Jeremy had his work cut out keeping up with the Opel.', 'Monkeys.', 'A giraffe on the right.', 'There.', 'Oh, it is!', 'Well, its probably a whole hippo.', 'Its just the rest of him is under the water.', 'James took over.', 'That ones lifting its paw up a bit like a dog does.', 'Paw.', 'Hoof.', 'Foot.', 'Whatever you call it.', 'Hoof.', 'Lets see.', 'Live with it.', 'Wow, there is an elephant right there.', 'Soon our route was blocked by a river and what youre supposed to do is wade in to check the depth.', 'Right.', 'Jeremy made us drive on until he got bored.', 'Here, now.', 'No.', 'I agree with him, for once, actually, because that reedy stuff must mean its shallow.', 'Ooh, hang on a minute.', 'Permission to say cock.', 'Its coming in!']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Reminder: these are the 3 data frames generated up to this point.\n",
    "# May_df\n",
    "# Clarkson_df\n",
    "# Hammond_df\n",
    "\n",
    "# Define the preprocessing function\n",
    "def preprocess_text(data):\n",
    "      \n",
    "   # Remove emails\n",
    "    data = [re.sub(r'\\S+@\\S+', '', i) for i in data]\n",
    "\n",
    "    # Remove newline characters\n",
    "    data = [i.replace('\\n', '').replace('\\r', '').strip() for i in data]\n",
    "\n",
    "    # Remove distracting single quotes\n",
    "    data = [i.replace(\"'\", \"\") for i in data]\n",
    "\n",
    "    return data\n",
    "\n",
    "# Convert 'text' column to list and then apply the preprocessing function to each dataframe\n",
    "\n",
    "May_data = preprocess_text(May_df['text'].values.tolist())\n",
    "Clarkson_data = preprocess_text(Clarkson_df['text'].values.tolist())\n",
    "Hammond_data = preprocess_text(Hammond_df['text'].values.tolist())\n",
    "\n",
    "print(May_data)\n",
    "# print(Clarkson_data)\n",
    "# print(Hammond_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisperx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
