{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Automatic Speech Recognition, Diarize and Label\n",
    "\n",
    "Environment = \"whisperx\"\n",
    "\n",
    "* Performance Benchmarks on local\n",
    "* GPU Benchmark: 0.09961056709289551 seconds\n",
    "* Memory Bandwidth Benchmark: 0.2920224666595459 seconds\n",
    "* CPU Benchmark: 13.046526432037354 seconds\n",
    "* Disk Write Benchmark: 2.3364615440368652 seconds\n",
    "* Disk Read Benchmark: 0.05882525444030762 seconds \\n\n",
    "  \n",
    "** all benchmarks are >> faster than Collab with the exception of Disk write.\n",
    "\n",
    "## Setup ⚙️\n",
    "Tested for PyTorch 2.0, Python 3.10 (use other versions at your own risk!)\n",
    "GPU execution requires the NVIDIA libraries cuBLAS 11.x and cuDNN 8.x to be installed on the system. Please refer to the CTranslate2 documentation.\n",
    "\n",
    "1.  Create Python3.10 environment\n",
    "\n",
    "`conda create --name whisperx python=3.10`\n",
    "\n",
    "`conda activate whisperx`\n",
    "\n",
    "2. Install PyTorch, e.g. for Linux and Windows CUDA11.8:\n",
    "   \n",
    "conda install pytorch==2.0.0 torchaudio==2.0.0 pytorch-cuda=11.8 -c pytorch -c nvidia\n",
    "\n",
    "See other methods here.\n",
    "\n",
    "1. Install this repo\n",
    "\n",
    "`pip install git+https://github.com/m-bain/whisperx.git`\n",
    "\n",
    "If already installed, update package to most recent commit\n",
    "\n",
    "`pip install git+https://github.com/m-bain/whisperx.git --upgrade`\n",
    "\n",
    "## Post Setup - REQUIRED for DIARIZATION\n",
    "https://github.com/m-bain/whisperX/issues/499\n",
    "\n",
    "`pip install pyannote.audio==3.0.1`\n",
    "\n",
    "`pip uninstall onnxruntime`\n",
    "\n",
    "`pip install --force-reinstall onnxruntime-gpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "\n",
    "## 1 - Convert Mp3 to WAV.\n",
    "\n",
    "def convert_m4a_to_mp3(input_file, output_file):\n",
    "    try:\n",
    "        ffmpeg.input(input_file).output(output_file).run(overwrite_output=True)\n",
    "        print(f\"Successfully converted {input_file} to {output_file}\")\n",
    "    except ffmpeg.Error as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "# Input/ output files and usage\n",
    "input_mp3 = './audio/Botswana_2007_Audio.mp3'  # Change this to your mp3 file path\n",
    "output_wav = './data/Botswana_2007_Audio.wav'  # Change this to your desired output wav file path\n",
    "\n",
    "convert_m4a_to_mp3(input_mp3, output_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jamie\\miniconda3\\envs\\whisperx\\lib\\inspect.py:869: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n",
      "c:\\Users\\jamie\\miniconda3\\envs\\whisperx\\lib\\site-packages\\pyannote\\audio\\pipelines\\speaker_verification.py:45: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  from speechbrain.pretrained import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully accessed the audio file: ./data/Botswana_2007_Audio.wav\n"
     ]
    }
   ],
   "source": [
    "import whisperx\n",
    "import gc\n",
    "import os\n",
    "import torch\n",
    "\n",
    "device = \"cuda\"\n",
    "## Full file should be the input (2007 or 2024 file..)\n",
    "audio_file = \"./data/Botswana_2007_Audio.wav\"\n",
    "\n",
    "## DEBUGGING, use a small file\n",
    "# audio_file = \"./data/Intro.wav\"\n",
    "\n",
    "batch_size = 16 # reduce if low on GPU mem\n",
    "compute_type = \"float16\" # change to \"int8\" if low on GPU mem (may reduce accuracy)\n",
    "without_timestamps= 'True'\n",
    "\n",
    "## Some error handling to ensure that successfully loaded the mp3 file!\n",
    "try:\n",
    "    # Check if the file exists\n",
    "    if not os.path.isfile(audio_file):\n",
    "        raise FileNotFoundError(f\"The file '{audio_file}' does not exist.\")\n",
    "    # Optionally, you can add more checks (like file format) here\n",
    "\n",
    "    print(f\"Successfully accessed the audio file: {audio_file}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jamie\\miniconda3\\envs\\whisperx\\lib\\inspect.py:869: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n",
      "c:\\Users\\jamie\\miniconda3\\envs\\whisperx\\lib\\site-packages\\pyannote\\audio\\pipelines\\speaker_verification.py:45: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  from speechbrain.pretrained import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully accessed the audio file: ./data/Botswana_2007_Audio.wav\n"
     ]
    }
   ],
   "source": [
    "import whisperx\n",
    "import gc\n",
    "import os\n",
    "import torch\n",
    "\n",
    "device = \"cuda\"\n",
    "## Full file should be the input (2007 or 2024 file..)\n",
    "audio_file = \"./data/Botswana_2007_Audio.wav\"\n",
    "\n",
    "## DEBUGGING, use a small file\n",
    "# audio_file = \"./data/Intro.wav\"\n",
    "\n",
    "batch_size = 16 # reduce if low on GPU mem\n",
    "compute_type = \"float16\" # change to \"int8\" if low on GPU mem (may reduce accuracy)\n",
    "without_timestamps= 'True'\n",
    "\n",
    "## Some error handling to ensure that successfully loaded the mp3 file!\n",
    "try:\n",
    "    # Check if the file exists\n",
    "    if not os.path.isfile(audio_file):\n",
    "        raise FileNotFoundError(f\"The file '{audio_file}' does not exist.\")\n",
    "    # Optionally, you can add more checks (like file format) here\n",
    "\n",
    "    print(f\"Successfully accessed the audio file: {audio_file}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcription in Batches\n",
    "\n",
    "### Split the Audio file into smaller pieces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3 - Split up large files in <10min\n",
    "\n",
    "\n",
    "import sqlite3\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import math\n",
    "\n",
    "\n",
    "# TODO: change max duration to 300 seconds\n",
    "# TODO: update the target database folder\n",
    "# TODO: check input filenames\n",
    "# TODO: Update the output folder\n",
    "\n",
    "# Function to split audio and save to database\n",
    "def split_audio(audio_file, max_duration=300):  # 60second (1min) for testing; 300sec for production\n",
    "    conn = sqlite3.connect('./data/Audio_clips.db')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''CREATE TABLE IF NOT EXISTS clips\n",
    "                     (id INTEGER PRIMARY KEY AUTOINCREMENT, start_time REAL, end_time REAL, filename TEXT)''')\n",
    "\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading audio file: {e}\")\n",
    "        return []\n",
    "\n",
    "    total_duration = librosa.get_duration(y=y, sr=sr)\n",
    "    num_splits = math.ceil(total_duration / max_duration)\n",
    "    results = []\n",
    "\n",
    "    for i in range(num_splits):\n",
    "        start_time = i * max_duration\n",
    "        end_time = min((i + 1) * max_duration, total_duration)\n",
    "\n",
    "        start_sample = int(start_time * sr)\n",
    "        end_sample = int(end_time * sr)\n",
    "\n",
    "        clip = y[start_sample:end_sample]\n",
    "        filename = f\"./data/Botswana2007_clip_{i}.wav\"\n",
    "\n",
    "        try:\n",
    "            sf.write(filename, clip, sr)\n",
    "            cursor.execute(\"INSERT INTO clips (start_time, end_time, filename) VALUES (?, ?, ?)\",\n",
    "                           (start_time, end_time, filename))\n",
    "            conn.commit()\n",
    "            results.append({\"start_time\": start_time, \"end_time\": end_time, \"filename\": filename})\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing clip {i}: {e}\")\n",
    "\n",
    "    conn.close()\n",
    "    return results\n",
    "# results is a DIctionary\n",
    "results = split_audio(audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BATCH PROCESS: Transcript - Align - Diarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1 - use python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSCRIBING & ALIGNING using device: cuda\n",
      "Compute type is float16\n",
      "Processing file: ./data/Testing\\Intro_clip_0.wav\n",
      "No language specified, language will be first be detected for each audio file (increases inference time).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\jamie\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "STARTING Transcription on ./data/Testing\\Intro_clip_0.wav\n",
      "Detected language: en (0.99) in first 30s of audio...\n",
      "[{'text': ' And welcome! Thank you very much. Now, as you know, the producers on this show like to give us challenges. Specifically, where they give us a very small amount of money and tell us to buy a used car. Then they set unbelievably hard tasks to do to see which one of us got the best deal. Yeah. This week, for a Top Gear special, they came up with a real humdinger. They gave each of us 1,500 quid and told us to go to Africa and buy a car.', 'start': 0.009, 'end': 28.302}, {'text': \" Yeah, there were just two conditions. It mustn't be four-wheel drive and it mustn't be built in any way to go off-road. The meeting point was the border post between Zimbabwe and Botswana. And, for once, I was the first to arrive.\", 'start': 28.302, 'end': 49.582}, {'text': \" Now, as you'd expect, I've done this properly. What I've got is a 1985 Mercedes-Benz 230e, a car that...\", 'start': 52.568, 'end': 59.991}]\n",
      "STARTING ALIGNMENT on ./data/Testing\\Intro_clip_0.wav\n",
      "STARTING DIARIZE on ./data/Testing\\Intro_clip_0.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import gc\n",
    "import torch\n",
    "import whisperx\n",
    "from HF_token import TOKEN_ID\n",
    "\n",
    "# Directory containing .wav files\n",
    "wav_directory = './data/Testing'\n",
    "\n",
    "# Get a list of all .wav files in the directory\n",
    "wav_files = glob.glob(os.path.join(wav_directory, '*.wav'))\n",
    "\n",
    "# Initialize results_full list\n",
    "aligned_results_full = []\n",
    "\n",
    "# Set device and compute type\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "compute_type = \"float16\" if device == \"cuda\" else \"float32\"\n",
    "\n",
    "print(f\"TRANSCRIBING & ALIGNING using device: {device}\")\n",
    "print(f\"Compute type is {compute_type}\")\n",
    "\n",
    "# Ensure the model directory exists\n",
    "model_dir = \"./model/\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 16  # Adjust as needed\n",
    "\n",
    "# # Load the model and save it to the local path\n",
    "# try:\n",
    "#     model = whisperx.load_model(\"large-v2\", device=device, compute_type=compute_type, download_root=model_dir)\n",
    "# except Exception as e:\n",
    "#     print(f\"Error loading model: {e}\")\n",
    "#     raise\n",
    "\n",
    "# Iterate through each .wav file and process it\n",
    "for wav_file in wav_files:\n",
    "    print(f\"Processing file: {wav_file}\")\n",
    "    try:\n",
    "        # Load the audio file\n",
    "        audio = whisperx.load_audio(wav_file)\n",
    "        \n",
    "        # Ensure the output directory exists\n",
    "        output_dir = \"./outputs/Testing\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        #####################     TRANSCRIPTION  #################\n",
    "        # Load the model and save it to the local path\n",
    "        try:\n",
    "            model = whisperx.load_model(\"large-v2\", device=device, compute_type=compute_type, download_root=model_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            raise\n",
    "\n",
    "        print(f\"STARTING Transcription on {wav_file}\")\n",
    "\n",
    "        # Transcribe the audio file\n",
    "        transcribe_result = model.transcribe(audio, batch_size=batch_size)\n",
    "        print(transcribe_result[\"segments\"])  # before alignment\n",
    "        \n",
    "        # Save the transcription result to a JSON file\n",
    "        transcript_filename = os.path.basename(wav_file).replace('.wav', '')\n",
    "        with open(f'./outputs/Testing/{transcript_filename}_transcript.json', 'w') as json_file:\n",
    "            json.dump(transcribe_result, json_file, indent=4)\n",
    "        \n",
    "        \n",
    "\n",
    "        #####################     ALIGNMENT #################\n",
    "        print(f\"STARTING ALIGNMENT on {wav_file}\")\n",
    "        \n",
    "        # Load the alignment model with the specified device\n",
    "        model_a, metadata = whisperx.load_align_model(language_code=\"en\", device=device)\n",
    "        \n",
    "        # Perform alignment using the specified device\n",
    "        aligned_result = whisperx.align(transcribe_result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=False)\n",
    "        \n",
    "        # Save the Alignment result to a JSON file\n",
    "        alignment_filename = os.path.basename(wav_file).replace('.wav', '')\n",
    "        with open(f'./outputs/Testing/{alignment_filename}_aligned.json', 'w') as json_file:\n",
    "            json.dump(aligned_result, json_file, indent=4)\n",
    "        \n",
    "        # Append the aligned result to results_full\n",
    "        aligned_results_full.append(aligned_result)\n",
    "        \n",
    "        #####################     DIARIZE #################\n",
    "        print(f\"STARTING DIARIZE on {wav_file}\")\n",
    "\n",
    "        # Load the DIARIZE Model\n",
    "        diarize_model = whisperx.DiarizationPipeline(use_auth_token=TOKEN_ID, device=device)\n",
    "\n",
    "        # Load the audio data\n",
    "        audio_data = {\n",
    "            'waveform': torch.from_numpy(audio[None, :]),\n",
    "            'sample_rate': whisperx.audio.SAMPLE_RATE\n",
    "                    }\n",
    "        # Run the diarization model\n",
    "        diarize_segments = diarize_model(audio)\n",
    "\n",
    "        # add min/max number of speakers if known\n",
    "        diarize_model(audio, min_speakers=1, max_speakers=3)\n",
    "\n",
    "        # Assign speaker labels to words\n",
    "        diarize_result = whisperx.assign_word_speakers(diarize_segments, aligned_result)\n",
    "\n",
    "        ## SAVE the TRANSCRIPT\n",
    "        diarized_filename = os.path.basename(wav_file).replace('.wav', '')\n",
    "        with open(f'./outputs/Testing/{diarized_filename}_diarized.json', 'w') as json_file:\n",
    "            json.dump(diarize_result, json_file, indent=4)\n",
    "     \n",
    "       # Clean up memory after each file\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {wav_file}: {e}\")\n",
    "\n",
    "# Optionally, save the full results to a single JSON file\n",
    "with open('./outputs/Testing/full_alignment.json', 'w') as json_file:\n",
    "    json.dump(aligned_results_full, json_file, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2 - use the Terminal and CLI \n",
    "This seemed to work on a single file VERY fast! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from HF_token import TOKEN_ID\n",
    "# Set the path to your directory\n",
    "directory = \"./data/Testing/\"\n",
    "\n",
    "# Iterate through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".wav\"):  # Check for .wav files\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Construct and run the whisperx command for each file\n",
    "        command = f\"whisperx {filepath} --model large-v2 --diarize --highlight_words True --hf_token {TOKEN_ID}\"\n",
    "        os.system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Approach 2B - add some subprocess to monitor progress\n",
    "\n",
    " This method is best as a) actually worked and b) provided insight into what is going on! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from HF_token import TOKEN_ID\n",
    "\n",
    "# Set the path to your directory\n",
    "directory = \"data/Testing/\"\n",
    "\n",
    "# Iterate through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".wav\"):  # Check for .wav files\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Print the filename to show progress\n",
    "        print(f\"Processing file: {filename}\")\n",
    "        \n",
    "        # Construct the whisperx command for each file\n",
    "        command = f\"whisperx {filepath} --model large-v2 --diarize --highlight_words True --hf_token {TOKEN_ID} --output_dir ./outputs\"\n",
    "        \n",
    "        # Run the command and capture real-time output\n",
    "        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        \n",
    "        # Display real-time output from the command\n",
    "        for line in process.stdout:\n",
    "            print(line.decode().strip())\n",
    "        \n",
    "        process.wait()  # Wait for process to finish\n",
    "        \n",
    "        # Confirm completion for each file\n",
    "        print(f\"Completed file: {filename}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.349</td>\n",
       "      <td>0.609</td>\n",
       "      <td>And welcome!</td>\n",
       "      <td>[{'word': 'And', 'start': 0.349, 'end': 0.409,...</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.749</td>\n",
       "      <td>1.690</td>\n",
       "      <td>Thank you very much.</td>\n",
       "      <td>[{'word': 'Thank', 'start': 0.749, 'end': 1.00...</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.070</td>\n",
       "      <td>7.893</td>\n",
       "      <td>Now, as you know, the producers on this show l...</td>\n",
       "      <td>[{'word': 'Now,', 'start': 3.07, 'end': 3.13, ...</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.193</td>\n",
       "      <td>11.874</td>\n",
       "      <td>Specifically, where they give us a very small ...</td>\n",
       "      <td>[{'word': 'Specifically,', 'start': 8.193, 'en...</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.195</td>\n",
       "      <td>17.257</td>\n",
       "      <td>Then they set unbelievably hard tasks to do to...</td>\n",
       "      <td>[{'word': 'Then', 'start': 12.195, 'end': 12.3...</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start     end                                               text  \\\n",
       "0   0.349   0.609                                       And welcome!   \n",
       "1   0.749   1.690                               Thank you very much.   \n",
       "2   3.070   7.893  Now, as you know, the producers on this show l...   \n",
       "3   8.193  11.874  Specifically, where they give us a very small ...   \n",
       "4  12.195  17.257  Then they set unbelievably hard tasks to do to...   \n",
       "\n",
       "                                               words     speaker  \n",
       "0  [{'word': 'And', 'start': 0.349, 'end': 0.409,...  SPEAKER_00  \n",
       "1  [{'word': 'Thank', 'start': 0.749, 'end': 1.00...  SPEAKER_00  \n",
       "2  [{'word': 'Now,', 'start': 3.07, 'end': 3.13, ...  SPEAKER_00  \n",
       "3  [{'word': 'Specifically,', 'start': 8.193, 'en...  SPEAKER_00  \n",
       "4  [{'word': 'Then', 'start': 12.195, 'end': 12.3...  SPEAKER_00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "\n",
    "# Directory containing the JSON files\n",
    "json_directory = 'outputs/Testing/'\n",
    "\n",
    "# Get a list of all JSON files in the directory\n",
    "json_files = glob.glob(os.path.join(json_directory, '*.json'))\n",
    "\n",
    "# Initialize a list to hold all DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Iterate through each JSON file and merge segments\n",
    "for json_file in json_files:\n",
    "\twith open(json_file, 'r') as file:\n",
    "\t\tdata = json.load(file)\n",
    "\t\t# Convert the \"segments\" part of the JSON data to a DataFrame\n",
    "\t\tdf = pd.DataFrame(data[\"segments\"])\n",
    "\t\tdf_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "diarized_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Display the consolidated DataFrame\n",
    "diarized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.349</td>\n",
       "      <td>0.609</td>\n",
       "      <td>And welcome!</td>\n",
       "      <td>[{'word': 'And', 'start': 0.349, 'end': 0.409,...</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.749</td>\n",
       "      <td>1.690</td>\n",
       "      <td>Thank you very much.</td>\n",
       "      <td>[{'word': 'Thank', 'start': 0.749, 'end': 1.00...</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.070</td>\n",
       "      <td>7.893</td>\n",
       "      <td>Now, as you know, the producers on this show l...</td>\n",
       "      <td>[{'word': 'Now,', 'start': 3.07, 'end': 3.13, ...</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.193</td>\n",
       "      <td>11.874</td>\n",
       "      <td>Specifically, where they give us a very small ...</td>\n",
       "      <td>[{'word': 'Specifically,', 'start': 8.193, 'en...</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.195</td>\n",
       "      <td>17.257</td>\n",
       "      <td>Then they set unbelievably hard tasks to do to...</td>\n",
       "      <td>[{'word': 'Then', 'start': 12.195, 'end': 12.3...</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start     end                                               text  \\\n",
       "0   0.349   0.609                                       And welcome!   \n",
       "1   0.749   1.690                               Thank you very much.   \n",
       "2   3.070   7.893  Now, as you know, the producers on this show l...   \n",
       "3   8.193  11.874  Specifically, where they give us a very small ...   \n",
       "4  12.195  17.257  Then they set unbelievably hard tasks to do to...   \n",
       "\n",
       "                                               words     speaker  \n",
       "0  [{'word': 'And', 'start': 0.349, 'end': 0.409,...  SPEAKER_00  \n",
       "1  [{'word': 'Thank', 'start': 0.749, 'end': 1.00...  SPEAKER_00  \n",
       "2  [{'word': 'Now,', 'start': 3.07, 'end': 3.13, ...  SPEAKER_00  \n",
       "3  [{'word': 'Specifically,', 'start': 8.193, 'en...  SPEAKER_00  \n",
       "4  [{'word': 'Then', 'start': 12.195, 'end': 12.3...  SPEAKER_00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Path to the JSON file\n",
    "json_file_path = 'Intro_clip_0.json'\n",
    "\n",
    "# Open and load the JSON file\n",
    "with open(json_file_path, 'r') as file:\n",
    "\tdata = json.load(file)\n",
    "\n",
    "# Convert the \"segments\" part of the JSON data to a DataFrame\n",
    "intro_clip_0_df = pd.DataFrame(data[\"segments\"])\n",
    "\n",
    "# Display the DataFrame\n",
    "intro_clip_0_df.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
