{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "\n",
    "#Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "#spacy\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#vis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "### Cant remember why needed this ... \n",
    "import locale\n",
    "def getpreferredencoding(do_setlocale=True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Import\n",
    "diarized_df = pd.read_csv('./data/diarzed_output_named.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21.467</td>\n",
       "      <td>23.068</td>\n",
       "      <td>Hello, hello, and welcome.</td>\n",
       "      <td>[{'word': 'Hello,', 'start': 21.467, 'end': 21...</td>\n",
       "      <td>Clarkson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23.108</td>\n",
       "      <td>24.029</td>\n",
       "      <td>Thank you very much.</td>\n",
       "      <td>[{'word': 'Thank', 'start': 23.108, 'end': 23....</td>\n",
       "      <td>Clarkson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>24.049</td>\n",
       "      <td>34.256</td>\n",
       "      <td>Now, as you know, the producers on this show l...</td>\n",
       "      <td>[{'word': 'Now,', 'start': 24.049, 'end': 24.1...</td>\n",
       "      <td>Clarkson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>34.597</td>\n",
       "      <td>39.640</td>\n",
       "      <td>Then they set unbelievably hard tasks to do to...</td>\n",
       "      <td>[{'word': 'Then', 'start': 34.597, 'end': 34.7...</td>\n",
       "      <td>Clarkson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>39.900</td>\n",
       "      <td>40.080</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>[{'word': 'Yeah.', 'start': 39.9, 'end': 40.08...</td>\n",
       "      <td>Hammond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>1042</td>\n",
       "      <td>269.865</td>\n",
       "      <td>271.447</td>\n",
       "      <td>We're through!</td>\n",
       "      <td>[{'word': \"We're\", 'start': 269.865, 'end': 27...</td>\n",
       "      <td>Clarkson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>1043</td>\n",
       "      <td>273.209</td>\n",
       "      <td>277.514</td>\n",
       "      <td>Both our cars were flooded, but our guides wer...</td>\n",
       "      <td>[{'word': 'Both', 'start': 273.209, 'end': 273...</td>\n",
       "      <td>SPEAKER_03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>1044</td>\n",
       "      <td>278.215</td>\n",
       "      <td>283.842</td>\n",
       "      <td>People of Surrey, if this happens to you, you ...</td>\n",
       "      <td>[{'word': 'People', 'start': 278.215, 'end': 2...</td>\n",
       "      <td>SPEAKER_03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>1045</td>\n",
       "      <td>283.922</td>\n",
       "      <td>286.085</td>\n",
       "      <td>Well, the people of Botswana have a tip for you.</td>\n",
       "      <td>[{'word': 'Well,', 'start': 283.922, 'end': 28...</td>\n",
       "      <td>SPEAKER_03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>1046</td>\n",
       "      <td>299.427</td>\n",
       "      <td>299.951</td>\n",
       "      <td>Meanwhile...</td>\n",
       "      <td>[{'word': 'Meanwhile...', 'start': 299.427, 'e...</td>\n",
       "      <td>SPEAKER_04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1047 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    start      end  \\\n",
       "0              0   21.467   23.068   \n",
       "1              1   23.108   24.029   \n",
       "2              2   24.049   34.256   \n",
       "3              3   34.597   39.640   \n",
       "4              4   39.900   40.080   \n",
       "...          ...      ...      ...   \n",
       "1042        1042  269.865  271.447   \n",
       "1043        1043  273.209  277.514   \n",
       "1044        1044  278.215  283.842   \n",
       "1045        1045  283.922  286.085   \n",
       "1046        1046  299.427  299.951   \n",
       "\n",
       "                                                   text  \\\n",
       "0                            Hello, hello, and welcome.   \n",
       "1                                  Thank you very much.   \n",
       "2     Now, as you know, the producers on this show l...   \n",
       "3     Then they set unbelievably hard tasks to do to...   \n",
       "4                                                 Yeah.   \n",
       "...                                                 ...   \n",
       "1042                                     We're through!   \n",
       "1043  Both our cars were flooded, but our guides wer...   \n",
       "1044  People of Surrey, if this happens to you, you ...   \n",
       "1045   Well, the people of Botswana have a tip for you.   \n",
       "1046                                       Meanwhile...   \n",
       "\n",
       "                                                  words     speaker  \n",
       "0     [{'word': 'Hello,', 'start': 21.467, 'end': 21...    Clarkson  \n",
       "1     [{'word': 'Thank', 'start': 23.108, 'end': 23....    Clarkson  \n",
       "2     [{'word': 'Now,', 'start': 24.049, 'end': 24.1...    Clarkson  \n",
       "3     [{'word': 'Then', 'start': 34.597, 'end': 34.7...    Clarkson  \n",
       "4     [{'word': 'Yeah.', 'start': 39.9, 'end': 40.08...     Hammond  \n",
       "...                                                 ...         ...  \n",
       "1042  [{'word': \"We're\", 'start': 269.865, 'end': 27...    Clarkson  \n",
       "1043  [{'word': 'Both', 'start': 273.209, 'end': 273...  SPEAKER_03  \n",
       "1044  [{'word': 'People', 'start': 278.215, 'end': 2...  SPEAKER_03  \n",
       "1045  [{'word': 'Well,', 'start': 283.922, 'end': 28...  SPEAKER_03  \n",
       "1046  [{'word': 'Meanwhile...', 'start': 299.427, 'e...  SPEAKER_04  \n",
       "\n",
       "[1047 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocessed_df = diarized_df.copy()\n",
    "# Preprocessing steps for LDA analysis\n",
    "\n",
    "preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocessed_df.to_csv(\"preprocess_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Below is a suggestion from gpt. \n",
    "from nltk.corpus.util import LazyCorpusLoader\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "# 1. Remove emails, newline characters, and non-alphabetic characters\n",
    "preprocessed_df['cleaned_text'] = preprocessed_df['text'].str.replace(r'\\S+@\\S+', '', regex=True)\n",
    "preprocessed_df['cleaned_text'] = preprocessed_df['cleaned_text'].str.replace(r'http\\S+|www\\S+', '', regex=True)\n",
    "preprocessed_df['cleaned_text'] = preprocessed_df['cleaned_text'].str.replace(r'\\n', ' ', regex=True)\n",
    "preprocessed_df['cleaned_text'] = preprocessed_df['cleaned_text'].str.replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "\n",
    "# 2. Convert to lowercase\n",
    "preprocessed_df['cleaned_text'] = preprocessed_df['cleaned_text'].str.lower()\n",
    "\n",
    "# 3. Tokenize the text\n",
    "preprocessed_df['tokens'] = preprocessed_df['cleaned_text'].apply(lambda x: gensim.utils.simple_preprocess(x, deacc=True))\n",
    "\n",
    "# 4. Remove stopwords\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "preprocessed_df['tokens'] = preprocessed_df['tokens'].apply(lambda x: [word for word in x if word not in stopwords])\n",
    "\n",
    "# 5. Lemmatize the tokens\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "preprocessed_df['lemmatized_tokens'] = preprocessed_df['tokens'].apply(lambda x: [token.lemma_ for token in nlp(\" \".join(x)) if token.pos_ in [\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]])\n",
    "\n",
    "# Display the preprocessed dataframe\n",
    "preprocessed_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisperx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
